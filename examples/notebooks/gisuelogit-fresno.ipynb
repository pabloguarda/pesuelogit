{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import isuelogit as isl\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main dir: /Users/pablo/github/gisuelogit\n"
     ]
    }
   ],
   "source": [
    "# Path management\n",
    "main_dir = str(Path(os.path.abspath('')).parents[1])\n",
    "os.chdir(main_dir)\n",
    "print('main dir:', main_dir)\n",
    "\n",
    "isl.config.dirs['read_network_data'] = \"input/network-data/fresno/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal modules\n",
    "from src.gisuelogit.models import UtilityParameters, BPRParameters, ODParameters, GISUELOGIT, NGD, compute_rr\n",
    "from src.gisuelogit.visualizations import plot_predictive_performance, plot_convergence_estimates, plot_top_od_flows_periods, plot_utility_parameters_periods, plot_rr_by_period\n",
    "from src.gisuelogit.networks import load_k_shortest_paths, read_paths, build_fresno_network, \\\n",
    "    Equilibrator, sparsify_OD, ColumnGenerator, read_OD\n",
    "from src.gisuelogit.etl import get_design_tensor, get_y_tensor, data_curation, temporal_split, add_period_id, get_tensors_by_year\n",
    "from src.gisuelogit.descriptive_statistics import mse, btcg_mse, mnrmse, nrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed for reproducibility\n",
    "_SEED = 2022\n",
    "np.random.seed(_SEED)\n",
    "random.seed(_SEED)\n",
    "tf.random.set_seed(_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Fresno network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresno_network = build_fresno_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read OD matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Q (1789, 1789) read in 0.0[s] with sparse format\n",
      "66266.3 trips were loaded among 6970 o-d pairs\n"
     ]
    }
   ],
   "source": [
    "read_OD(network=fresno_network, sparse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Read paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18289 paths were read in 16.1[s]              \n",
      "\n",
      "18289 paths were loaded in the network\n",
      "\n",
      "Updating incidence matrices\n",
      "\n",
      "Matrix D (2413, 18289) generated in 14.0[s]               \n",
      "\n",
      "Matrix M (6970, 18289) generated in 5.1[s]               \n",
      "\n",
      "Matrix C (18289, 18289) generated in 4.5[s]               \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#read_paths(network=fresno_network, update_incidence_matrices=True, filename='paths-fresno.csv')\n",
    "read_paths(network=fresno_network, update_incidence_matrices=True, filename = 'paths-full-model-fresno.csv')\n",
    "\n",
    "# For quick testing\n",
    "# Q = fresno_network.load_OD(sparsify_OD(fresno_network.Q, prop_od_pairs=0.99))\n",
    "# load_k_shortest_paths(network=fresno_network, k=2, update_incidence_matrices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read spatiotemporal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderpath = isl.config.dirs['read_network_data'] + 'links/spatiotemporal-data/'\n",
    "df = pd.concat([pd.read_csv(file) for file in glob.glob(folderpath + \"*link-data*\")], axis=0)\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "# Select data from Tuesday to Thursday\n",
    "df = df[df['date'].dt.dayofweek.between(1, 3)]\n",
    "# df = df[df['date'].dt.year == 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    hour  period_id\n",
      "11     6          0\n",
      "12     7          1\n",
      "13     8          2\n",
      "14     9          3\n",
      "0     10          4\n",
      "1     11          5\n",
      "2     12          6\n",
      "3     13          7\n",
      "4     14          8\n",
      "5     15          9\n",
      "6     16         10\n",
      "7     17         11\n",
      "8     18         12\n",
      "9     19         13\n",
      "10    20         14\n"
     ]
    }
   ],
   "source": [
    "# Add period id for timevarying estimation\n",
    "\n",
    "period_feature = 'hour'\n",
    "\n",
    "df['period'] = df['date'].astype(str) + '-' + df[period_feature].astype(str)\n",
    "# df['period'] = df.period.map(hash)\n",
    "\n",
    "df = add_period_id(df, period_feature='hour')\n",
    "\n",
    "period_keys = df[[period_feature,'period_id']].drop_duplicates().reset_index().drop('index',axis =1).sort_values('hour')\n",
    "print(period_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "            link_key  observed  counts  capacity [veh]  tt_ff [min]  \\\n0     (0, 1621, '0')         0     NaN          1800.0        0.098   \n1  (1239, 1630, '0')         0     NaN             inf        0.000   \n2    (228, 192, '0')         1  1667.0          2400.0        0.110   \n3  (1243, 1631, '0')         0     NaN             inf        0.000   \n4  (1244, 1632, '0')         0     NaN             inf        0.000   \n\n   speed_ff[mi/hr]      inrix_id  pems_ids link_type   id  ...  median_age  \\\n0               45  1.626616e+09        []     LWRLK    1  ...        31.1   \n1            99999           NaN        []     DMDLK  565  ...         0.0   \n2               65  1.626659e+09  [602350]     LWRLK  564  ...        16.6   \n3            99999           NaN        []     DMDLK  563  ...         0.0   \n4            99999           NaN        []     DMDLK  562  ...         0.0   \n\n   incidents  bus_stops  intersections       date  hour  tf_inrix  year  \\\n0          0          0              1 2019-10-01    10     0.221  2019   \n1          0          0              0 2019-10-01    10     0.000  2019   \n2          0          0              0 2019-10-01    10     0.112  2019   \n3          0          0              0 2019-10-01    10     0.000  2019   \n4          0          0              0 2019-10-01    10     0.000  2019   \n\n          period  period_id  \n0  2019-10-01-10          4  \n1  2019-10-01-10          4  \n2  2019-10-01-10          4  \n3  2019-10-01-10          4  \n4  2019-10-01-10          4  \n\n[5 rows x 43 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>link_key</th>\n      <th>observed</th>\n      <th>counts</th>\n      <th>capacity [veh]</th>\n      <th>tt_ff [min]</th>\n      <th>speed_ff[mi/hr]</th>\n      <th>inrix_id</th>\n      <th>pems_ids</th>\n      <th>link_type</th>\n      <th>id</th>\n      <th>...</th>\n      <th>median_age</th>\n      <th>incidents</th>\n      <th>bus_stops</th>\n      <th>intersections</th>\n      <th>date</th>\n      <th>hour</th>\n      <th>tf_inrix</th>\n      <th>year</th>\n      <th>period</th>\n      <th>period_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(0, 1621, '0')</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>1800.0</td>\n      <td>0.098</td>\n      <td>45</td>\n      <td>1.626616e+09</td>\n      <td>[]</td>\n      <td>LWRLK</td>\n      <td>1</td>\n      <td>...</td>\n      <td>31.1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2019-10-01</td>\n      <td>10</td>\n      <td>0.221</td>\n      <td>2019</td>\n      <td>2019-10-01-10</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(1239, 1630, '0')</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>inf</td>\n      <td>0.000</td>\n      <td>99999</td>\n      <td>NaN</td>\n      <td>[]</td>\n      <td>DMDLK</td>\n      <td>565</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2019-10-01</td>\n      <td>10</td>\n      <td>0.000</td>\n      <td>2019</td>\n      <td>2019-10-01-10</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(228, 192, '0')</td>\n      <td>1</td>\n      <td>1667.0</td>\n      <td>2400.0</td>\n      <td>0.110</td>\n      <td>65</td>\n      <td>1.626659e+09</td>\n      <td>[602350]</td>\n      <td>LWRLK</td>\n      <td>564</td>\n      <td>...</td>\n      <td>16.6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2019-10-01</td>\n      <td>10</td>\n      <td>0.112</td>\n      <td>2019</td>\n      <td>2019-10-01-10</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(1243, 1631, '0')</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>inf</td>\n      <td>0.000</td>\n      <td>99999</td>\n      <td>NaN</td>\n      <td>[]</td>\n      <td>DMDLK</td>\n      <td>563</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2019-10-01</td>\n      <td>10</td>\n      <td>0.000</td>\n      <td>2019</td>\n      <td>2019-10-01-10</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(1244, 1632, '0')</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>inf</td>\n      <td>0.000</td>\n      <td>99999</td>\n      <td>NaN</td>\n      <td>[]</td>\n      <td>DMDLK</td>\n      <td>562</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2019-10-01</td>\n      <td>10</td>\n      <td>0.000</td>\n      <td>2019</td>\n      <td>2019-10-01-10</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 43 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "       speed_ref_avg  speed_hist_avg     speed_max\ncount   1.013460e+06    1.009583e+06  1.013460e+06\nmean    1.924470e+01    1.767589e+01  2.051278e+01\nstd     1.982261e+01    1.909664e+01  2.140424e+01\nmin     0.000000e+00    0.000000e+00  0.000000e+00\n25%     0.000000e+00    0.000000e+00  0.000000e+00\n50%     2.112700e+01    1.755400e+01  2.112700e+01\n75%     2.796200e+01    2.547600e+01  3.106900e+01\nmax     6.772900e+01    7.891400e+01  8.388500e+01",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>speed_ref_avg</th>\n      <th>speed_hist_avg</th>\n      <th>speed_max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.013460e+06</td>\n      <td>1.009583e+06</td>\n      <td>1.013460e+06</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.924470e+01</td>\n      <td>1.767589e+01</td>\n      <td>2.051278e+01</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.982261e+01</td>\n      <td>1.909664e+01</td>\n      <td>2.140424e+01</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.112700e+01</td>\n      <td>1.755400e+01</td>\n      <td>2.112700e+01</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2.796200e+01</td>\n      <td>2.547600e+01</td>\n      <td>3.106900e+01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>6.772900e+01</td>\n      <td>7.891400e+01</td>\n      <td>8.388500e+01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Units in miles per hour\n",
    "df[['speed_ref_avg','speed_hist_avg','speed_max']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['link_key', 'observed', 'counts', 'capacity [veh]', 'tt_ff [min]',\n       'speed_ff[mi/hr]', 'inrix_id', 'pems_ids', 'link_type', 'id', 'rhoj',\n       'lane', 'ff_speed', 'length', 'alpha', 'beta', 'tf', 'k', 'inrix_id.1',\n       'speed_avg', 'speed_ref_avg', 'speed_hist_avg', 'tt_avg', 'speed_max',\n       'speed_sd', 'speed_cv', 'speed_hist_sd', 'speed_ref_sd', 'tt_sd',\n       'tt_var', 'tt_cv', 'road_closures', 'median_inc', 'median_age',\n       'incidents', 'bus_stops', 'intersections', 'date', 'hour', 'tf_inrix',\n       'year', 'period', 'period_id'],\n      dtype='object')"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tt_ff'] = np.where(df['link_type'] != 'LWRLK', 0,df['length']/df['speed_ref_avg'])\n",
    "df.loc[(df.link_type == \"LWRLK\") & (df.speed_ref_avg == 0),'tt_ff'] = float('nan')\n",
    "\n",
    "df['tt_avg'] = np.where(df['link_type'] != 'LWRLK', 0,df['length']/df['speed_hist_avg'])\n",
    "df.loc[(df.link_type == \"LWRLK\") & (df.speed_hist_avg == 0),'tt_avg'] = float('nan')\n",
    "\n",
    "tt_sd_adj = df.groupby(['period_id','link_key'])[['tt_avg']].std().reset_index().rename(columns = {'tt_avg': 'tt_sd_adj'})\n",
    "\n",
    "df = df.merge(tt_sd_adj, on = ['period_id','link_key'])\n",
    "\n",
    "df = data_curation(df)\n",
    "\n",
    "df['tt_sd'] = df['tt_sd_adj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Units of travel time features are converted from hours to minutes\n",
    "df['tt_sd'] = df['tt_sd']*60\n",
    "df['tt_avg'] = df['tt_avg']*60\n",
    "df['tt_ff'] = df['tt_ff']*60"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "       speed_ref_avg  speed_hist_avg         tt_ff         tt_avg  \\\ncount   1.013460e+06    1.009583e+06  1.013460e+06  887813.000000   \nmean    1.924470e+01    1.767589e+01  2.038423e-01       0.219493   \nstd     1.982261e+01    1.909664e+01  2.610045e-01       0.262030   \nmin     0.000000e+00    0.000000e+00  0.000000e+00       0.000000   \n25%     0.000000e+00    0.000000e+00  0.000000e+00       0.000000   \n50%     2.112700e+01    1.755400e+01  1.497376e-01       0.167050   \n75%     2.796200e+01    2.547600e+01  2.792397e-01       0.312986   \nmax     6.772900e+01    7.891400e+01  4.220601e+00       3.827439   \n\n          tt_sd_adj  \ncount  1.013460e+06  \nmean   3.022799e-04  \nstd    4.638521e-04  \nmin    0.000000e+00  \n25%    0.000000e+00  \n50%    1.856268e-04  \n75%    4.248116e-04  \nmax    1.243267e-02  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>speed_ref_avg</th>\n      <th>speed_hist_avg</th>\n      <th>tt_ff</th>\n      <th>tt_avg</th>\n      <th>tt_sd_adj</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.013460e+06</td>\n      <td>1.009583e+06</td>\n      <td>1.013460e+06</td>\n      <td>887813.000000</td>\n      <td>1.013460e+06</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.924470e+01</td>\n      <td>1.767589e+01</td>\n      <td>2.038423e-01</td>\n      <td>0.219493</td>\n      <td>3.022799e-04</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.982261e+01</td>\n      <td>1.909664e+01</td>\n      <td>2.610045e-01</td>\n      <td>0.262030</td>\n      <td>4.638521e-04</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.112700e+01</td>\n      <td>1.755400e+01</td>\n      <td>1.497376e-01</td>\n      <td>0.167050</td>\n      <td>1.856268e-04</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2.796200e+01</td>\n      <td>2.547600e+01</td>\n      <td>2.792397e-01</td>\n      <td>0.312986</td>\n      <td>4.248116e-04</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>6.772900e+01</td>\n      <td>7.891400e+01</td>\n      <td>4.220601e+00</td>\n      <td>3.827439</td>\n      <td>1.243267e-02</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['speed_ref_avg','speed_hist_avg', 'tt_ff', 'tt_avg','tt_sd_adj']].describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_Z = ['tt_sd', 'median_inc', 'incidents', 'bus_stops', 'intersections']\n",
    "# features_Z = ['speed_sd', 'median_inc', 'incidents', 'bus_stops', 'intersections']\n",
    "\n",
    "\n",
    "utility_parameters = UtilityParameters(features_Y=['tt'],\n",
    "                                       features_Z=features_Z,\n",
    "                                       initial_values={'tt': 0, 'c': 0, 's': 0, 'psc_factor': 0,\n",
    "                                                       'fixed_effect': np.zeros_like(fresno_network.links)},\n",
    "                                       signs={'tt': '-', 'tt_sd': '-', 'median_inc': '+', 'incidents': '-',\n",
    "                                              'bus_stops': '-', 'intersections': '-'},\n",
    "                                       trainables={'psc_factor': False, 'fixed_effect': False},\n",
    "                                       )\n",
    "\n",
    "utility_parameters.constant_initializer(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_links = len(fresno_network.links)\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "df['year'] = df.date.dt.year\n",
    "X, Y = {}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "             counts          tt_ff         tt_avg       tf_inrix  \\\ncount  31624.000000  542925.000000  468303.000000  542925.000000   \nmean    1761.140959       0.204903       0.221931       0.200169   \nstd      770.228931       0.262226       0.266852       0.228208   \nmin        1.000000       0.000000       0.000000       0.000000   \n25%     1249.000000       0.000000       0.000000       0.000000   \n50%     1686.000000       0.150455       0.168820       0.152000   \n75%     2162.450000       0.282111       0.318261       0.280000   \nmax     4807.000000       4.220601       3.827439       2.302000   \n\n               tt_sd  \ncount  542925.000000  \nmean        0.018137  \nstd         0.027831  \nmin         0.000000  \n25%         0.000000  \n50%         0.011138  \n75%         0.025489  \nmax         0.745960  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>counts</th>\n      <th>tt_ff</th>\n      <th>tt_avg</th>\n      <th>tf_inrix</th>\n      <th>tt_sd</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>31624.000000</td>\n      <td>542925.000000</td>\n      <td>468303.000000</td>\n      <td>542925.000000</td>\n      <td>542925.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1761.140959</td>\n      <td>0.204903</td>\n      <td>0.221931</td>\n      <td>0.200169</td>\n      <td>0.018137</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>770.228931</td>\n      <td>0.262226</td>\n      <td>0.266852</td>\n      <td>0.228208</td>\n      <td>0.027831</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1249.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1686.000000</td>\n      <td>0.150455</td>\n      <td>0.168820</td>\n      <td>0.152000</td>\n      <td>0.011138</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2162.450000</td>\n      <td>0.282111</td>\n      <td>0.318261</td>\n      <td>0.280000</td>\n      <td>0.025489</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>4807.000000</td>\n      <td>4.220601</td>\n      <td>3.827439</td>\n      <td>2.302000</td>\n      <td>0.745960</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('year == 2019')[['counts', 'tt_ff', 'tt_avg', 'tf_inrix', 'tt_sd']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "             counts          tt_ff         tt_avg       tf_inrix  \\\ncount  27472.000000  470535.000000  419510.000000  470535.000000   \nmean    1605.127777       0.202618       0.216770       0.198494   \nstd      743.713869       0.259583       0.256512       0.226003   \nmin        6.000000       0.000000       0.000000       0.000000   \n25%     1108.450000       0.000000       0.000000       0.000000   \n50%     1528.900000       0.149437       0.165341       0.150000   \n75%     1978.000000       0.274658       0.306717       0.273000   \nmax     4766.000000       4.220601       3.274444       2.113000   \n\n               tt_sd  \ncount  470535.000000  \nmean        0.018137  \nstd         0.027831  \nmin         0.000000  \n25%         0.000000  \n50%         0.011138  \n75%         0.025489  \nmax         0.745960  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>counts</th>\n      <th>tt_ff</th>\n      <th>tt_avg</th>\n      <th>tf_inrix</th>\n      <th>tt_sd</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>27472.000000</td>\n      <td>470535.000000</td>\n      <td>419510.000000</td>\n      <td>470535.000000</td>\n      <td>470535.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1605.127777</td>\n      <td>0.202618</td>\n      <td>0.216770</td>\n      <td>0.198494</td>\n      <td>0.018137</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>743.713869</td>\n      <td>0.259583</td>\n      <td>0.256512</td>\n      <td>0.226003</td>\n      <td>0.027831</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>6.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1108.450000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1528.900000</td>\n      <td>0.149437</td>\n      <td>0.165341</td>\n      <td>0.150000</td>\n      <td>0.011138</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1978.000000</td>\n      <td>0.274658</td>\n      <td>0.306717</td>\n      <td>0.273000</td>\n      <td>0.025489</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>4766.000000</td>\n      <td>4.220601</td>\n      <td>3.274444</td>\n      <td>2.113000</td>\n      <td>0.745960</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('year == 2020')[['counts', 'tt_ff', 'tt_avg', 'tf_inrix', 'tt_sd']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set free flow travel times\n",
    "tt_ff_links = df.groupby('link_key')['tt_ff'].min()\n",
    "for link in fresno_network.links:\n",
    "    fresno_network.links_dict[link.key].performance_function.tf = float(tt_ff_links[tt_ff_links.index==str(link.key)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "          counts    tt_avg\ncounts  1.000000  0.055122\ntt_avg  0.055122  1.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>counts</th>\n      <th>tt_avg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>counts</th>\n      <td>1.000000</td>\n      <td>0.055122</td>\n    </tr>\n    <tr>\n      <th>tt_avg</th>\n      <td>0.055122</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This correlation should be positive\n",
    "df[['counts','tt_avg']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check that there is a balanced amount of observations per date\n",
    "obs_date = df.groupby('date')['hour'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "            speed_sd  speed_avg       counts  total_obs\ndate                                                   \n2019-10-01  1.731787  17.175187  1770.335035      36195\n2019-10-02  1.760109  17.169768  1746.651824      36195\n2019-10-03  1.754288  17.092304  1785.115209      36195\n2019-10-08  1.847060  18.165569  1747.732955      36195\n2019-10-09  1.917923  18.137042  1756.834846      36195\n2019-10-10  1.830232  18.107925  1793.512340      36195\n2019-10-15  1.831527  18.114384  1750.339155      36195\n2019-10-16  1.823680  18.162625  1760.170975      36195\n2019-10-17  1.832219  18.080860  1775.411385      36195\n2019-10-22  1.837839  18.175561  1738.314834      36195\n2019-10-23  1.864443  18.222690  1753.243283      36195\n2019-10-24  1.848827  18.184814  1746.626881      36195\n2019-10-29  1.868430  18.167171  1731.246241      36195\n2019-10-30  1.816364  18.109232  1757.581055      36195\n2019-10-31  1.882446  18.128430  1804.595108      36195\n2020-10-01  1.290377  19.579215  1616.266052      36195\n2020-10-06  1.365919  19.709670  1581.200095      36195\n2020-10-07  1.327017  19.927088  1587.425957      36195\n2020-10-08  1.344382  19.969943  1604.360618      36195\n2020-10-13  1.311842  19.626350  1607.663262      36195\n2020-10-14  1.300075  19.558364  1613.399054      36195\n2020-10-15  1.331493  19.621633  1637.123641      36195\n2020-10-20  1.353743  19.597736  1599.044113      36195\n2020-10-21  1.325694  19.501768  1587.235083      36195\n2020-10-22  1.334320  19.591921  1628.075697      36195\n2020-10-27  1.309348  19.573460  1583.478061      36195\n2020-10-28  1.324270  19.646064  1593.821986      36195\n2020-10-29  1.336212  19.557279  1627.548269      36195",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>speed_sd</th>\n      <th>speed_avg</th>\n      <th>counts</th>\n      <th>total_obs</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-10-01</th>\n      <td>1.731787</td>\n      <td>17.175187</td>\n      <td>1770.335035</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2019-10-02</th>\n      <td>1.760109</td>\n      <td>17.169768</td>\n      <td>1746.651824</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2019-10-03</th>\n      <td>1.754288</td>\n      <td>17.092304</td>\n      <td>1785.115209</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2019-10-08</th>\n      <td>1.847060</td>\n      <td>18.165569</td>\n      <td>1747.732955</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2019-10-09</th>\n      <td>1.917923</td>\n      <td>18.137042</td>\n      <td>1756.834846</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2019-10-10</th>\n      <td>1.830232</td>\n      <td>18.107925</td>\n      <td>1793.512340</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2019-10-15</th>\n      <td>1.831527</td>\n      <td>18.114384</td>\n      <td>1750.339155</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2019-10-16</th>\n      <td>1.823680</td>\n      <td>18.162625</td>\n      <td>1760.170975</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2019-10-17</th>\n      <td>1.832219</td>\n      <td>18.080860</td>\n      <td>1775.411385</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2019-10-22</th>\n      <td>1.837839</td>\n      <td>18.175561</td>\n      <td>1738.314834</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2019-10-23</th>\n      <td>1.864443</td>\n      <td>18.222690</td>\n      <td>1753.243283</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2019-10-24</th>\n      <td>1.848827</td>\n      <td>18.184814</td>\n      <td>1746.626881</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2019-10-29</th>\n      <td>1.868430</td>\n      <td>18.167171</td>\n      <td>1731.246241</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2019-10-30</th>\n      <td>1.816364</td>\n      <td>18.109232</td>\n      <td>1757.581055</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2019-10-31</th>\n      <td>1.882446</td>\n      <td>18.128430</td>\n      <td>1804.595108</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2020-10-01</th>\n      <td>1.290377</td>\n      <td>19.579215</td>\n      <td>1616.266052</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2020-10-06</th>\n      <td>1.365919</td>\n      <td>19.709670</td>\n      <td>1581.200095</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2020-10-07</th>\n      <td>1.327017</td>\n      <td>19.927088</td>\n      <td>1587.425957</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2020-10-08</th>\n      <td>1.344382</td>\n      <td>19.969943</td>\n      <td>1604.360618</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2020-10-13</th>\n      <td>1.311842</td>\n      <td>19.626350</td>\n      <td>1607.663262</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2020-10-14</th>\n      <td>1.300075</td>\n      <td>19.558364</td>\n      <td>1613.399054</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2020-10-15</th>\n      <td>1.331493</td>\n      <td>19.621633</td>\n      <td>1637.123641</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2020-10-20</th>\n      <td>1.353743</td>\n      <td>19.597736</td>\n      <td>1599.044113</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2020-10-21</th>\n      <td>1.325694</td>\n      <td>19.501768</td>\n      <td>1587.235083</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2020-10-22</th>\n      <td>1.334320</td>\n      <td>19.591921</td>\n      <td>1628.075697</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2020-10-27</th>\n      <td>1.309348</td>\n      <td>19.573460</td>\n      <td>1583.478061</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2020-10-28</th>\n      <td>1.324270</td>\n      <td>19.646064</td>\n      <td>1593.821986</td>\n      <td>36195</td>\n    </tr>\n    <tr>\n      <th>2020-10-29</th>\n      <td>1.336212</td>\n      <td>19.557279</td>\n      <td>1627.548269</td>\n      <td>36195</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stats by date\n",
    "df.groupby('date')[['speed_sd','speed_avg', 'counts']].mean().assign(total_obs = obs_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Link attributes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "              tt_sd    median_inc     incidents     bus_stops  intersections\ncount  1.013460e+06  1.013460e+06  1.013460e+06  1.013460e+06   1.013460e+06\nmean   1.813680e-02  2.621913e+01  7.441093e-01  1.500207e-01   8.765023e-01\nstd    2.783112e-02  2.135738e+01  3.193143e+00  4.411927e-01   1.319496e+00\nmin    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   0.000000e+00\n25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   0.000000e+00\n50%    1.113761e-02  2.482100e+01  0.000000e+00  0.000000e+00   0.000000e+00\n75%    2.548870e-02  4.168100e+01  0.000000e+00  0.000000e+00   1.000000e+00\nmax    7.459602e-01  1.158930e+02  4.000000e+01  4.000000e+00   9.000000e+00",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tt_sd</th>\n      <th>median_inc</th>\n      <th>incidents</th>\n      <th>bus_stops</th>\n      <th>intersections</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.013460e+06</td>\n      <td>1.013460e+06</td>\n      <td>1.013460e+06</td>\n      <td>1.013460e+06</td>\n      <td>1.013460e+06</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.813680e-02</td>\n      <td>2.621913e+01</td>\n      <td>7.441093e-01</td>\n      <td>1.500207e-01</td>\n      <td>8.765023e-01</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.783112e-02</td>\n      <td>2.135738e+01</td>\n      <td>3.193143e+00</td>\n      <td>4.411927e-01</td>\n      <td>1.319496e+00</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.113761e-02</td>\n      <td>2.482100e+01</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2.548870e-02</td>\n      <td>4.168100e+01</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>1.000000e+00</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>7.459602e-01</td>\n      <td>1.158930e+02</td>\n      <td>4.000000e+01</td>\n      <td>4.000000e+00</td>\n      <td>9.000000e+00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[features_Z].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-02 00:46:44.624008: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Include only data between 4pm and 5pm\n",
    "# X, Y = get_tensors_by_year(df, features_Z = features_Z, network = fresno_network)\n",
    "#X, Y = get_tensors_by_year(df[df.hour.isin([7])], features_Z = features_Z, network = fresno_network)\n",
    "X, Y = get_tensors_by_year(df[df.hour.isin([16])], features_Z = features_Z, network = fresno_network)\n",
    "# X, Y = get_tensors_by_year(df[df.hour.isin([15,16,17])], features_Z = features_Z, network = fresno_network)\n",
    "#X, Y = get_tensors_by_year(df[df.hour.isin([6,7,8])], features_Z = features_Z, network = fresno_network)\n",
    "\n",
    "# Include hourly data between 6AM and 8PM (15 hour intervals)\n",
    "# XT, YT = get_tensors_by_year(df, features_Z = features_Z)\n",
    "#XT, YT = get_tensors_by_year(df[df.hour.isin(range(15,16))], features_Z = features_Z, network = fresno_network)\n",
    "XT, YT = get_tensors_by_year(df[df.hour.isin([6,7,8, 15,16,17])], features_Z = features_Z, network = fresno_network)\n",
    "#XT, YT = get_tensors_by_year(df[df.hour.isin([6,7,8])], features_Z = features_Z, network = fresno_network)\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = temporal_split(X[2019].numpy(), Y[2019].numpy(), n_days = X[2019].shape[0])\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = X[2020], X[2019], Y[2020], Y[2019]\n",
    "X_train, X_test, Y_train, Y_test = X[2019], X[2020], Y[2019], Y[2020]\n",
    "XT_train, XT_test, YT_train, YT_test = XT[2019], XT[2020], YT[2019], YT[2020]\n",
    "\n",
    "# Remove validation set to reduce computation costs\n",
    "X_test, Y_test = None, None\n",
    "XT_test, YT_test = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network equilibrium predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "equilibrator = Equilibrator(\n",
    "    network=fresno_network,\n",
    "    # paths_generator=paths_generator,\n",
    "    utility=utility_parameters,\n",
    "    max_iters=100,\n",
    "    method='fw',\n",
    "    iters_fw=50,\n",
    "    accuracy=1e-4,\n",
    ")\n",
    "\n",
    "column_generator = ColumnGenerator(equilibrator=equilibrator,\n",
    "                                   utility=utility_parameters,\n",
    "                                   n_paths=0,\n",
    "                                   ods_coverage=0.1,\n",
    "                                   ods_sampling='sequential',\n",
    "                                   # ods_sampling='demand',\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_LOSS_WEIGHTS: {'od': 0, 'tt': 1, 'flow': 1, 'eq_flow': 1}, _MOMENTUM_EQUILIBRIUM: {'lue': 0.99, 'odlue': 0.99, 'odlulpe': 0.99, 'tvodlulpe': 0.99}, epochs {'learning': 200, 'equilibrium': 50}\n"
     ]
    }
   ],
   "source": [
    "# For testing\n",
    "# _EPOCHS = {'learning': 4, 'equilibrium': 2}\n",
    "_EPOCHS = {'learning': 200, 'equilibrium': 50}\n",
    "_BATCH_SIZE = 16\n",
    "_LR = 5e-1\n",
    "_RELATIVE_GAP = 1e-5\n",
    "_XTICKS_SPACING = 50\n",
    "_EPOCHS_PRINT_INTERVAL = 1\n",
    "\n",
    "# When adding fixed effects, all parameters of the utility function are idenfiable but provided that the utility coefficients are period specific. The\n",
    "# only attribute that is always identifiable is the standard deviation of travel time because it changes over hours for same link. Overall, removing fixed effect ease the identification of the parameters of the utility function.\n",
    "_FIXED_EFFECT = False\n",
    "# features_Z = ['tt_sd']\n",
    "\n",
    "# Excluding historic OD gives more freedom for the model to find an equilibria and minimize reconstruction error\n",
    "_LOSS_WEIGHTS ={'od': 0, 'tt': 1, 'flow': 1, 'eq_flow': 1}\n",
    "\n",
    "# _LOSS_METRIC  = mnrmse\n",
    "# _MOMENTUM_EQUILIBRIUM = {'lue': 0.95, 'odlue': 0.95, 'odlulpe': 0.95, 'tvodlulpe':0.95}\n",
    "\n",
    "# NRMSE encourages a larger reduction in link flow loss and it does not requires to add much momentum to the equilibrium loss component\n",
    "_LOSS_METRIC  = nrmse\n",
    "_MOMENTUM_EQUILIBRIUM = {'lue': 0.99, 'odlue': 0.99, 'odlulpe': 0.99, 'tvodlulpe':0.99}\n",
    "# _MOMENTUM_EQUILIBRIUM = {'lue': 0.95, 'odlue': 0.95, 'odlulpe': 0.95, 'tvodlulpe':0.95}\n",
    "#_MOMENTUM_EQUILIBRIUM = {'lue': 0.8, 'odlue': 0.8, 'odlulpe': 0.8, 'tvodlulpe':0.8}\n",
    "\n",
    "# Including historic OD matrix\n",
    "# _LOSS_WEIGHTS ={'od': 1, 'tt': 1, 'flow': 1, 'eq_flow': 1}\n",
    "# _MOMENTUM_EQUILIBRIUM = 0.99\n",
    "\n",
    "# _LOSS_METRIC = mse\n",
    "# _LOSS_WEIGHTS ={'od': 1, 'theta': 0, 'tt': 1e10, 'flow': 1, 'eq_flow': 1}\n",
    "\n",
    "print(f\"_LOSS_WEIGHTS: {_LOSS_WEIGHTS}, _MOMENTUM_EQUILIBRIUM: {_MOMENTUM_EQUILIBRIUM}, \"\n",
    "      f\"epochs { _EPOCHS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model = dict.fromkeys(['lue', 'odlue','odlulpe', 'tvodlulpe'], True)\n",
    "# run_model = dict.fromkeys(['lue', 'odlue','odlulpe', 'tvodlulpe'], False)\n",
    "\n",
    "# run_model['lue'] = True\n",
    "# run_model['odlue'] = True\n",
    "# run_model['odlulpe'] = True\n",
    "run_model['tvodlulpe'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "train_results_dfs = {}\n",
    "test_results_dfs = {}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model 1: Benchmark of gisuelogit and isuelogit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LUE: Benchmark of gisuelogit and isuelogit (utility only)\n",
      "\n",
      "Epoch: 0/200, n_periods: 1,  n_train: 15\n",
      "0: train_loss=1.8e+06, val_loss=0, train_loss tt=0.15, val_loss tt=0, train_loss flow=1.8e+06, val_loss flow=0, theta = [0. 0. 0. 0. 0. 0.], avg rr = nan, psc_factor = 0.0, avg theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=3.2e-29, lambda eq=1, relative x=2.1e-16, relative gap=1e-05, train flow equilibrium loss=1.4e-25, time: 13.4\n",
      "\n",
      "Epoch: 1/200, n_periods: 1,  n_train: 15\n",
      "1: train_loss=6.6e+05, val_loss=0, train_loss tt=0.14, val_loss tt=0, train_loss flow=1.7e+06, val_loss flow=0, theta = [-0.5   -0.496  0.    -0.5    0.    -0.5  ], avg rr = 0.99, psc_factor = 0.0, avg theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=3.2e-29, lambda eq=0.34, relative x=0.19, relative gap=20, train flow equilibrium loss=2.9e+05, time: 19.5\n",
      "\n",
      "Epoch: 2/200, n_periods: 1,  n_train: 15\n",
      "2: train_loss=6.3e+05, val_loss=0, train_loss tt=0.14, val_loss tt=0, train_loss flow=1.6e+06, val_loss flow=0, theta = [-0.821 -0.995  0.    -0.798  0.    -0.826], avg rr = 1.21, psc_factor = 0.0, avg theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=3.2e-29, lambda eq=0.34, relative x=0.2, relative gap=0.58, train flow equilibrium loss=2.8e+05, time: 18.8\n",
      "\n",
      "Epoch: 3/200, n_periods: 1,  n_train: 15\n",
      "3: train_loss=5.9e+05, val_loss=0, train_loss tt=0.13, val_loss tt=0, train_loss flow=1.5e+06, val_loss flow=0, theta = [-1.061 -1.473  0.    -1.016  0.    -1.078], avg rr = 1.39, psc_factor = 0.0, avg theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=3.2e-29, lambda eq=0.34, relative x=0.21, relative gap=0.27, train flow equilibrium loss=2.7e+05, time: 20.0\n",
      "\n",
      "Epoch: 4/200, n_periods: 1,  n_train: 15\n",
      "4: train_loss=5.6e+05, val_loss=0, train_loss tt=0.13, val_loss tt=0, train_loss flow=1.4e+06, val_loss flow=0, theta = [-1.252 -1.928  0.    -1.188  0.    -1.286], avg rr = 1.54, psc_factor = 0.0, avg theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=3.2e-29, lambda eq=0.34, relative x=0.21, relative gap=0.17, train flow equilibrium loss=2.6e+05, time: 18.2\n",
      "\n",
      "Epoch: 5/200, n_periods: 1,  n_train: 15\n",
      "5: train_loss=5.2e+05, val_loss=0, train_loss tt=0.12, val_loss tt=0, train_loss flow=1.3e+06, val_loss flow=0, theta = [-1.41  -2.364  0.    -1.327  0.    -1.463], avg rr = 1.68, psc_factor = 0.0, avg theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=3.2e-29, lambda eq=0.34, relative x=0.23, relative gap=0.12, train flow equilibrium loss=2.5e+05, time: 17.9\n",
      "\n",
      "Epoch: 6/200, n_periods: 1,  n_train: 15\n",
      "6: train_loss=4.9e+05, val_loss=0, train_loss tt=0.12, val_loss tt=0, train_loss flow=1.3e+06, val_loss flow=0, theta = [-1.542 -2.784  0.    -1.442  0.    -1.619], avg rr = 1.81, psc_factor = 0.0, avg theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=3.2e-29, lambda eq=0.35, relative x=0.24, relative gap=0.092, train flow equilibrium loss=2.4e+05, time: 18.5\n",
      "\n",
      "Epoch: 7/200, n_periods: 1,  n_train: 15\n",
      "7: train_loss=4.6e+05, val_loss=0, train_loss tt=0.12, val_loss tt=0, train_loss flow=1.2e+06, val_loss flow=0, theta = [-1.656 -3.189  0.    -1.537  0.    -1.758], avg rr = 1.93, psc_factor = 0.0, avg theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=3.2e-29, lambda eq=0.35, relative x=0.25, relative gap=0.072, train flow equilibrium loss=2.2e+05, time: 19.3\n",
      "\n",
      "Epoch: 8/200, n_periods: 1,  n_train: 15\n",
      "8: train_loss=4.3e+05, val_loss=0, train_loss tt=0.12, val_loss tt=0, train_loss flow=1.1e+06, val_loss flow=0, theta = [-1.756 -3.573  0.    -1.618  0.    -1.88 ], avg rr = 2.03, psc_factor = 0.0, avg theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=3.2e-29, lambda eq=0.35, relative x=0.26, relative gap=0.058, train flow equilibrium loss=2.1e+05, time: 23.0\n",
      "\n",
      "Epoch: 9/200, n_periods: 1,  n_train: 15\n",
      "9: train_loss=4.1e+05, val_loss=0, train_loss tt=0.11, val_loss tt=0, train_loss flow=1e+06, val_loss flow=0, theta = [-1.845 -3.933  0.    -1.687  0.    -1.988], avg rr = 2.13, psc_factor = 0.0, avg theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=3.2e-29, lambda eq=0.35, relative x=0.27, relative gap=0.048, train flow equilibrium loss=2e+05, time: 21.7\n"
     ]
    }
   ],
   "source": [
    "if run_model['lue']:\n",
    "    print('\\nLUE: Benchmark of gisuelogit and isuelogit (utility only)')\n",
    "\n",
    "    # _MOMENTUM_EQUILIBRIUM = 1\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=_LR)\n",
    "\n",
    "    utility_parameters = UtilityParameters(features_Y=['tt'],\n",
    "                                           features_Z=features_Z,\n",
    "                                           # initial_values ={'tt': -1, 'tt_sd': -1,\n",
    "                                           #                  'median_inc': 1,\n",
    "                                           #                  'incidents': -1, 'bus_stops': -1, 'intersections': -1,\n",
    "                                           #                  'psc_factor': 0, 'fixed_effect': np.zeros_like(fresno_network.links)},\n",
    "                                           initial_values={'psc_factor': 0,\n",
    "                                                           'fixed_effect': np.zeros_like(fresno_network.links)},\n",
    "                                           signs={'tt': '-', 'tt_sd': '-', 'median_inc': '+', 'incidents': '-',\n",
    "                                                  'bus_stops': '-', 'intersections': '-'},\n",
    "                                           trainables={'psc_factor': False, 'fixed_effect': _FIXED_EFFECT,\n",
    "                                                       'tt': True, 'tt_sd': True,\n",
    "                                                       # 'median_inc': False, 'incidents': False,\n",
    "                                                       # 'bus_stops': False, 'intersections': False,\n",
    "                                                       'median_inc': True, 'incidents': True,\n",
    "                                                       'bus_stops': True, 'intersections': True\n",
    "                                                       },\n",
    "                                           time_varying = True\n",
    "                                           )\n",
    "\n",
    "    bpr_parameters = BPRParameters(keys=['alpha', 'beta'],\n",
    "                                   initial_values={'alpha': 0.15, 'beta': 4},\n",
    "                                   trainables=dict.fromkeys(['alpha', 'beta'], False),\n",
    "                                   )\n",
    "\n",
    "    od_parameters = ODParameters(key='od',\n",
    "                                 initial_values=fresno_network.q.flatten(),\n",
    "                                 true_values=fresno_network.q.flatten(),\n",
    "                                 historic_values={1: fresno_network.q.flatten()},\n",
    "                                 trainable=False)\n",
    "\n",
    "    equilibrator = Equilibrator(\n",
    "        network=fresno_network,\n",
    "        utility=utility_parameters,\n",
    "        max_iters=100,\n",
    "        method='fw',\n",
    "        iters_fw=50,\n",
    "        accuracy=1e-4,\n",
    "    )\n",
    "\n",
    "    column_generator = ColumnGenerator(equilibrator=equilibrator,\n",
    "                                       utility=utility_parameters,\n",
    "                                       n_paths=0,\n",
    "                                       ods_coverage=0.1,\n",
    "                                       ods_sampling='sequential',\n",
    "                                       )\n",
    "\n",
    "    lue = GISUELOGIT(\n",
    "        key='lue',\n",
    "        network=fresno_network,\n",
    "        dtype=tf.float64,\n",
    "        equilibrator = equilibrator,\n",
    "        utility=utility_parameters,\n",
    "        bpr=bpr_parameters,\n",
    "        od=od_parameters,\n",
    "        n_periods = len(np.unique(X_train[:,:,-1].numpy().flatten()))\n",
    "    )\n",
    "\n",
    "    train_results_dfs['lue'], test_results_dfs['lue'] = lue.train(\n",
    "        X_train, Y_train, X_test, Y_test,\n",
    "        optimizer=optimizer,\n",
    "        batch_size=_BATCH_SIZE,\n",
    "        threshold_relative_gap=_RELATIVE_GAP,\n",
    "        momentum_equilibrium = _MOMENTUM_EQUILIBRIUM['lue'],\n",
    "        loss_weights= dict(_LOSS_WEIGHTS, od = 0),\n",
    "        loss_metric=_LOSS_METRIC,\n",
    "        epochs_print_interval=_EPOCHS_PRINT_INTERVAL,\n",
    "        epochs=_EPOCHS)\n",
    "\n",
    "    # Relative loss curves over epochs\n",
    "    plot_predictive_performance(train_losses=train_results_dfs['lue'], val_losses=test_results_dfs['lue'],\n",
    "                                xticks_spacing = _XTICKS_SPACING)\n",
    "\n",
    "    # Compute utility parameters over time (heatmap) and value of travel time reliability (lineplot)\n",
    "    theta_df = plot_utility_parameters_periods(lue, period_keys = period_keys, period_feature='hour')\n",
    "\n",
    "    plot_rr_by_period(theta_df)\n",
    "\n",
    "    # Average reliability ratio over epochs\n",
    "    plot_convergence_estimates(estimates=train_results_dfs['lue'].\\\n",
    "                       assign(rr = train_results_dfs['lue']['tt_sd']/train_results_dfs['lue']['tt'])[['epoch','rr']],\n",
    "                           xticks_spacing = _XTICKS_SPACING)\n",
    "\n",
    "    plt.ylabel('average reliability ratio')\n",
    "\n",
    "    # Distribution of fixed effects\n",
    "    sns.displot(pd.DataFrame({'fixed_effect':np.array(lue.fixed_effect)}),\n",
    "        x=\"fixed_effect\", multiple=\"stack\", kind=\"kde\", alpha = 0.8)\n",
    "\n",
    "    #print(f\"theta = {dict(zip(utility_parameters.true_values.keys(), list(lue.theta.numpy())))}\")\n",
    "    print(f\"theta:\\n\\n\\ {theta_df.assign(rr = theta_df['tt_sd']/theta_df['tt'])}\")\n",
    "    print(f\"alpha = {lue.alpha: 0.2f}, beta  = {lue.beta: 0.2f}\")\n",
    "    print(f\"Avg abs diff of observed and estimated OD: {np.mean(np.abs(lue.q - fresno_network.q.flatten())): 0.2f}\")\n",
    "    print(f\"Avg observed OD: {np.mean(np.abs(fresno_network.q.flatten())): 0.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model 2: OD + utility estimation with historic OD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if run_model['odlue']:\n",
    "\n",
    "    # _MOMENTUM_EQUILIBRIUM = 0.99\n",
    "\n",
    "    print('\\nODLUE: OD + utility estimation with historic OD')\n",
    "\n",
    "    # _RELATIVE_GAP = 1e-4\\\n",
    "    # _XTICKS_SPACING = 50\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=_LR)\n",
    "    # optimizer = tf.keras.optimizers.Adagrad(learning_rate=_LR)\n",
    "    utility_parameters = UtilityParameters(features_Y=['tt'],\n",
    "                                           features_Z=features_Z,\n",
    "                                           # initial_values ={'tt': -1, 'tt_sd': -1,\n",
    "                                           #                  'median_inc': 1,\n",
    "                                           #                  'incidents': -1, 'bus_stops': -1, 'intersections': -1,\n",
    "                                           #                  'psc_factor': 0, 'fixed_effect': np.zeros_like(fresno_network.links)},\n",
    "                                           initial_values={'psc_factor': 0,\n",
    "                                                           'fixed_effect': np.zeros_like(fresno_network.links)},\n",
    "                                           signs={'tt': '-', 'tt_sd': '-', 'median_inc': '+', 'incidents': '-',\n",
    "                                                  'bus_stops': '-', 'intersections': '-'},\n",
    "                                           trainables={'psc_factor': False, 'fixed_effect': _FIXED_EFFECT,\n",
    "                                                       'tt': True, 'tt_sd': True,\n",
    "                                                       # 'median_inc': False, 'incidents': False,\n",
    "                                                       # 'bus_stops': False, 'intersections': False,\n",
    "                                                       'median_inc': True, 'incidents': True,\n",
    "                                                       'bus_stops': True, 'intersections': True\n",
    "                                                       },\n",
    "                                           time_varying = True\n",
    "                                           )\n",
    "\n",
    "    bpr_parameters = BPRParameters(keys=['alpha', 'beta'],\n",
    "                                   initial_values={'alpha': 0.15, 'beta': 4},\n",
    "                                   trainables=dict.fromkeys(['alpha', 'beta'], False),\n",
    "                                   )\n",
    "\n",
    "    od_parameters = ODParameters(key='od',\n",
    "                                 initial_values=fresno_network.q.flatten(),\n",
    "                                 historic_values={1: fresno_network.q.flatten()},\n",
    "                                 trainable=True)\n",
    "\n",
    "    equilibrator = Equilibrator(\n",
    "        network=fresno_network,\n",
    "        # paths_generator=paths_generator,\n",
    "        utility=utility_parameters,\n",
    "        max_iters=100,\n",
    "        method='fw',\n",
    "        iters_fw=50,\n",
    "        accuracy=1e-4,\n",
    "    )\n",
    "\n",
    "    column_generator = ColumnGenerator(equilibrator=equilibrator,\n",
    "                                       utility=utility_parameters,\n",
    "                                       n_paths=0,\n",
    "                                       ods_coverage=0.1,\n",
    "                                       ods_sampling='sequential',\n",
    "                                       # ods_sampling='demand',\n",
    "                                       )\n",
    "\n",
    "    odlue = GISUELOGIT(\n",
    "        key='odlue',\n",
    "        network=fresno_network,\n",
    "        dtype=tf.float64,\n",
    "        equilibrator=equilibrator,\n",
    "        column_generator=column_generator,\n",
    "        utility=utility_parameters,\n",
    "        bpr=bpr_parameters,\n",
    "        od=od_parameters,\n",
    "        n_periods = len(np.unique(X_train[:,:,-1].numpy().flatten()))\n",
    "    )\n",
    "\n",
    "    train_results_dfs['odlue'], test_results_dfs['odlue'] = odlue.train(\n",
    "        X_train, Y_train, X_test, Y_test,\n",
    "        optimizer=optimizer,\n",
    "        batch_size=_BATCH_SIZE,\n",
    "        # generalization_error={'train': False, 'validation': True},\n",
    "        loss_weights= _LOSS_WEIGHTS,\n",
    "        loss_metric=_LOSS_METRIC,\n",
    "        momentum_equilibrium = _MOMENTUM_EQUILIBRIUM['odlue'],\n",
    "        threshold_relative_gap=_RELATIVE_GAP,\n",
    "        epochs_print_interval=_EPOCHS_PRINT_INTERVAL,\n",
    "        epochs=_EPOCHS)\n",
    "\n",
    "    plot_predictive_performance(train_losses=train_results_dfs['odlue'], val_losses=test_results_dfs['odlue'],\n",
    "                                xticks_spacing = _XTICKS_SPACING)\n",
    "\n",
    "    plot_top_od_flows_periods(odlue,\n",
    "                              historic_od= fresno_network.q.flatten(),\n",
    "                              period_keys = period_keys,\n",
    "                              period_feature='hour', top_k=20)\n",
    "\n",
    "    # Compute utility parameters over time (heatmap) and value of travel time reliability (lineplot)\n",
    "    theta_df = plot_utility_parameters_periods(odlue, period_keys = period_keys, period_feature='hour')\n",
    "\n",
    "    plot_rr_by_period(theta_df)\n",
    "\n",
    "    plot_convergence_estimates(estimates=train_results_dfs['odlue'].\\\n",
    "                       assign(rr = train_results_dfs['odlue']['tt_sd']/train_results_dfs['odlue']['tt'])[['epoch','rr']],\n",
    "                           xticks_spacing = _XTICKS_SPACING)\n",
    "    plt.ylabel('average reliability ratio')\n",
    "\n",
    "    sns.displot(pd.DataFrame({'fixed_effect':np.array(odlue.fixed_effect)}),\n",
    "            x=\"fixed_effect\", multiple=\"stack\", kind=\"kde\", alpha = 0.8)\n",
    "\n",
    "    #print(f\"theta = {dict(zip(utility_parameters.true_values.keys(), list(odlue.theta.numpy())))}\")\n",
    "    print(f\"theta:\\n\\n\\ {theta_df.assign(rr = theta_df['tt_sd']/theta_df['tt'])}\")\n",
    "    print(f\"alpha = {odlue.alpha: 0.2f}, beta  = {odlue.beta: 0.2f}\")\n",
    "    print(f\"Avg abs diff of observed and estimated OD: {np.mean(np.abs(odlue.q - fresno_network.q.flatten())): 0.2f}\")\n",
    "    print(f\"Avg observed OD: {np.mean(np.abs(fresno_network.q.flatten())): 0.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model 3: ODLUE + link specific performance parameters (alphas and betas)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if run_model['odlulpe']:\n",
    "\n",
    "    print('\\nODLULPE: ODLUE + link performance parameters with historic OD matrix (link specifics alphas and betas)')\n",
    "\n",
    "    # _MOMENTUM_EQUILIBRIUM = 0.99\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=_LR)\n",
    "\n",
    "    # _LR = 5e-1\n",
    "    # _RELATIVE_GAP = 1e-5\n",
    "\n",
    "    # Some initializations of the bpr parameters, makes the optimization to fail (e.g. alpha =1, beta = 1). Using a common\n",
    "    # alpha but different betas for every link make the estimation more stable but there is overfitting after a certain amount of iterations\n",
    "\n",
    "    bpr_parameters = BPRParameters(keys=['alpha', 'beta'],\n",
    "                                   initial_values={'alpha': 0.15*np.ones_like(fresno_network.links,dtype = np.float32),\n",
    "                                                   'beta': 4*np.ones_like(fresno_network.links,dtype = np.float32)},\n",
    "                                   trainables={'alpha': True, 'beta': True},\n",
    "                                   # trainables={'alpha': False, 'beta': True},\n",
    "                                   )\n",
    "\n",
    "    od_parameters = ODParameters(key='od',\n",
    "                                 initial_values=fresno_network.q.flatten(),\n",
    "                                 historic_values={1: fresno_network.q.flatten()},\n",
    "                                 trainable=True\n",
    "                                 )\n",
    "\n",
    "    utility_parameters = UtilityParameters(features_Y=['tt'],\n",
    "                                           features_Z=features_Z,\n",
    "                                           # initial_values ={'tt': -1, 'tt_sd': -1,\n",
    "                                           #                  'median_inc': 1,\n",
    "                                           #                  'incidents': -1, 'bus_stops': -1, 'intersections': -1,\n",
    "                                           #                  'psc_factor': 0, 'fixed_effect': np.zeros_like(fresno_network.links)},\n",
    "                                           initial_values={'psc_factor': 0,\n",
    "                                                           'fixed_effect': np.zeros_like(fresno_network.links)},\n",
    "                                           signs={'tt': '-', 'tt_sd': '-',\n",
    "                                                  'median_inc': '+', 'incidents': '-',\n",
    "                                                  'bus_stops': '-', 'intersections': '-'\n",
    "                                                  },\n",
    "                                           trainables={'psc_factor': False, 'fixed_effect': _FIXED_EFFECT,\n",
    "                                                       'tt': True, 'tt_sd': True,\n",
    "                                                       # 'median_inc': False, 'incidents': False,\n",
    "                                                       # 'bus_stops': False, 'intersections': False,\n",
    "                                                       'median_inc': True, 'incidents': True,\n",
    "                                                       'bus_stops': True, 'intersections': True\n",
    "                                                       },\n",
    "                                           time_varying = True\n",
    "                                           )\n",
    "\n",
    "    equilibrator = Equilibrator(\n",
    "        network=fresno_network,\n",
    "        # paths_generator=paths_generator,\n",
    "        utility=utility_parameters,\n",
    "        max_iters=100,\n",
    "        method='fw',\n",
    "        iters_fw=50,\n",
    "        accuracy=1e-4,\n",
    "    )\n",
    "\n",
    "    column_generator = ColumnGenerator(equilibrator=equilibrator,\n",
    "                                       utility=utility_parameters,\n",
    "                                       n_paths=0,\n",
    "                                       ods_coverage=0.1,\n",
    "                                       ods_sampling='sequential',\n",
    "                                       # ods_sampling='demand',\n",
    "                                       )\n",
    "\n",
    "    odlulpe = GISUELOGIT(\n",
    "        key='odlulpe',\n",
    "        network=fresno_network,\n",
    "        dtype=tf.float64,\n",
    "        equilibrator=equilibrator,\n",
    "        column_generator=column_generator,\n",
    "        utility=utility_parameters,\n",
    "        bpr=bpr_parameters,\n",
    "        od=od_parameters,\n",
    "        n_periods = len(np.unique(X_train[:,:,-1].numpy().flatten()))\n",
    "    )\n",
    "\n",
    "    train_results_dfs['odlulpe'], test_results_dfs['odlulpe'] = odlulpe.train(\n",
    "        X_train, Y_train, X_test, Y_test,\n",
    "        optimizer=optimizer,\n",
    "        # generalization_error={'train': False, 'validation': True},\n",
    "        batch_size=_BATCH_SIZE,\n",
    "        # loss_weights={'od': 1, 'theta': 0, 'tt': 1, 'flow': 1, 'eq_flow': 1},\n",
    "        loss_weights=_LOSS_WEIGHTS,\n",
    "        momentum_equilibrium = _MOMENTUM_EQUILIBRIUM['odlulpe'],\n",
    "        threshold_relative_gap=_RELATIVE_GAP,\n",
    "        epochs_print_interval=_EPOCHS_PRINT_INTERVAL,\n",
    "        loss_metric=_LOSS_METRIC,\n",
    "        epochs=_EPOCHS)\n",
    "\n",
    "\n",
    "\n",
    "    plot_predictive_performance(train_losses=train_results_dfs['odlulpe'], val_losses=test_results_dfs['odlulpe'],\n",
    "                                xticks_spacing = _XTICKS_SPACING)\n",
    "\n",
    "    plot_convergence_estimates(estimates=train_results_dfs['odlulpe'][['epoch','alpha','beta']],\n",
    "                                xticks_spacing = _XTICKS_SPACING)\n",
    "\n",
    "    sns.displot(pd.melt(pd.DataFrame({'alpha':odlulpe.alpha, 'beta': odlulpe.beta}), var_name = 'parameters'),\n",
    "                x=\"value\", hue=\"parameters\", multiple=\"stack\", kind=\"kde\", alpha = 0.8)\n",
    "\n",
    "    top_q, total_trips_by_hour = plot_top_od_flows_periods(odlulpe,\n",
    "                                                           historic_od= fresno_network.q.flatten(),\n",
    "                                                           period_keys = period_keys,\n",
    "                                                           period_feature='hour', top_k=20)\n",
    "\n",
    "    # Compute utility parameters over time (heatmap) and value of travel time reliability (lineplot)\n",
    "    theta_df = plot_utility_parameters_periods(odlulpe, period_keys = period_keys, period_feature='hour')\n",
    "\n",
    "    plot_rr_by_period(theta_df)\n",
    "\n",
    "\n",
    "    plot_convergence_estimates(estimates=train_results_dfs['odlulpe'].\\\n",
    "                   assign(rr = train_results_dfs['odlulpe']['tt_sd']/train_results_dfs['odlulpe']['tt'])[['epoch','rr']],\n",
    "                       xticks_spacing = _XTICKS_SPACING)\n",
    "\n",
    "    plt.ylabel('average reliability ratio')\n",
    "\n",
    "    sns.displot(pd.DataFrame({'fixed_effect':np.array(odlulpe.fixed_effect)}),\n",
    "                x=\"fixed_effect\", multiple=\"stack\", kind=\"kde\", alpha = 0.8)\n",
    "\n",
    "    #print(f\"theta = {dict(zip(utility_parameters.true_values.keys(), list(odlulpe.theta.numpy())))}\")\n",
    "    print(f\"theta:\\n\\n\\ {theta_df.assign(rr = theta_df['tt_sd']/theta_df['tt'])}\")\n",
    "    print(f\"alpha = {np.mean(odlulpe.alpha): 0.2f}, beta  = {np.mean(odlulpe.beta): 0.2f}\")\n",
    "    print(f\"Avg abs diff of observed and estimated OD: {np.mean(np.abs(odlulpe.q - fresno_network.q.flatten())): 0.2f}\")\n",
    "    print(f\"Avg observed OD: {np.mean(np.abs(fresno_network.q.flatten())): 0.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model 4: TVODLULPE (ODLULPE with Time Varying OD and Utility Function)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if run_model['tvodlulpe']:\n",
    "    print('\\ntvodlulpe: Time specific utility and OD, link performance parameters, no historic OD')\n",
    "\n",
    "    _FIXED_EFFECT = False\n",
    "\n",
    "    # Only in this model, we can add fixed effect and have identifiable utility function coefficients\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=_LR)\n",
    "\n",
    "    utility_parameters = UtilityParameters(features_Y=['tt'],\n",
    "                                           features_Z=features_Z,\n",
    "                                           # initial_values ={'tt': -1, 'tt_sd': -1,\n",
    "                                           #                  'median_inc': 1,\n",
    "                                           #                  'incidents': -1, 'bus_stops': -1, 'intersections': -1,\n",
    "                                           #                  'psc_factor': 0, 'fixed_effect': np.zeros_like(fresno_network.links)},\n",
    "                                           initial_values={'tt': 0, 'tt_sd': 0, 's': 0, 'psc_factor': 0,\n",
    "                                                           'fixed_effect': np.zeros_like(fresno_network.links)},\n",
    "                                           signs={'tt': '-',\n",
    "                                                  'tt_sd': '-',\n",
    "                                                  'median_inc': '+', 'incidents': '-',\n",
    "                                                  'bus_stops': '-', 'intersections': '-'\n",
    "                                                  },\n",
    "                                           trainables={'psc_factor': False, 'fixed_effect': _FIXED_EFFECT,\n",
    "                                                       'tt': True, 'tt_sd': True,\n",
    "                                                       # 'median_inc': False, 'incidents': False,\n",
    "                                                       # 'bus_stops': False, 'intersections': False,\n",
    "                                                       'median_inc': True, 'incidents': True,\n",
    "                                                       'bus_stops': True, 'intersections': True\n",
    "                                                       },\n",
    "                                           time_varying=True,\n",
    "                                           )\n",
    "\n",
    "    bpr_parameters = BPRParameters(keys=['alpha', 'beta'],\n",
    "                                   initial_values={'alpha': 0.15*np.ones_like(fresno_network.links,dtype = np.float32),\n",
    "                                                   'beta': 4*np.ones_like(fresno_network.links,dtype = np.float32)},\n",
    "                                   # trainables={'alpha': True, 'beta': True},\n",
    "                                   trainables={'alpha': True, 'beta': False},\n",
    "                                   )\n",
    "\n",
    "    od_parameters = ODParameters(key='od',\n",
    "                                 initial_values=fresno_network.q.flatten(),\n",
    "                                 true_values=fresno_network.q.flatten(),\n",
    "                                 historic_values={1: fresno_network.q.flatten()},\n",
    "                                 time_varying=True,\n",
    "                                 trainable=True)\n",
    "\n",
    "    tvodlulpe = GISUELOGIT(\n",
    "        key='tvodlulpe',\n",
    "        network=fresno_network,\n",
    "        dtype=tf.float64,\n",
    "        utility=utility_parameters,\n",
    "        bpr=bpr_parameters,\n",
    "        od=od_parameters,\n",
    "        n_periods = len(np.unique(XT_train[:,:,-1].numpy().flatten()))\n",
    "    )\n",
    "\n",
    "    train_results_dfs['tvodlulpe'], test_results_dfs['tvodlulpe'] = tvodlulpe.train(\n",
    "        XT_train, YT_train, XT_test, YT_test,\n",
    "        optimizer=optimizer,\n",
    "        # generalization_error={'train': False, 'validation': True},\n",
    "        batch_size=_BATCH_SIZE,\n",
    "        loss_weights= _LOSS_WEIGHTS,\n",
    "        loss_metric=_LOSS_METRIC,\n",
    "        momentum_equilibrium=_MOMENTUM_EQUILIBRIUM['tvodlulpe'],\n",
    "        threshold_relative_gap=_RELATIVE_GAP,\n",
    "        epochs=_EPOCHS)\n",
    "\n",
    "    plot_predictive_performance(train_losses=train_results_dfs['tvodlulpe'], val_losses=test_results_dfs['tvodlulpe'],\n",
    "                               xticks_spacing=_XTICKS_SPACING)\n",
    "\n",
    "    plot_convergence_estimates(estimates=train_results_dfs['tvodlulpe'][['epoch', 'alpha', 'beta']],\n",
    "                               xticks_spacing=_XTICKS_SPACING)\n",
    "\n",
    "    sns.displot(pd.melt(pd.DataFrame({'alpha':tvodlulpe.alpha, 'beta': tvodlulpe.beta}), var_name = 'parameters'),\n",
    "                x=\"value\", hue=\"parameters\", multiple=\"stack\", kind=\"kde\", alpha = 0.8)\n",
    "\n",
    "    top_q, total_trips_by_hour = plot_top_od_flows_periods(tvodlulpe,\n",
    "                                                           period_keys = period_keys,\n",
    "                                                           historic_od= fresno_network.q.flatten(),\n",
    "                                                           period_feature='hour', top_k=20)\n",
    "\n",
    "    # Compute utility parameters over time (heatmap) and value of travel time reliability (lineplot)\n",
    "    theta_df = plot_utility_parameters_periods(tvodlulpe, period_keys = period_keys, period_feature='hour')\n",
    "\n",
    "    plot_rr_by_period(theta_df)\n",
    "\n",
    "    plot_convergence_estimates(estimates=train_results_dfs['tvodlulpe'].\\\n",
    "               assign(rr = train_results_dfs['tvodlulpe']['tt_sd']/train_results_dfs['tvodlulpe']['tt'])[['epoch','rr']],\n",
    "                   xticks_spacing = _XTICKS_SPACING)\n",
    "    plt.ylabel('average reliability ratio')\n",
    "\n",
    "    sns.displot(pd.DataFrame({'fixed_effect': np.array(tvodlulpe.fixed_effect)}),\n",
    "                x=\"fixed_effect\", multiple=\"stack\", kind=\"kde\", alpha=0.8)\n",
    "\n",
    "    # print(f\"theta = {dict(zip(utility_parameters.true_values.keys(), list(tvodlulpe.theta.numpy())))}\")\n",
    "    print(f\"theta:\\n\\n\\ {theta_df.assign(rr = theta_df['tt_sd']/theta_df['tt'])}\")\n",
    "    print(f\"alpha = {np.mean(tvodlulpe.alpha): 0.2f}, beta  = {np.mean(tvodlulpe.beta): 0.2f}\")\n",
    "    print(f\"Avg abs diff of observed and estimated OD: {np.mean(np.abs(tvodlulpe.q - fresno_network.q.flatten())): 0.2f}\")\n",
    "    print(f\"Avg observed OD: {np.mean(np.abs(fresno_network.q.flatten())): 0.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write csv file with estimation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_results_df, test_results_df \\\n",
    "    = map(lambda x: pd.concat([results.assign(model = model)[['model'] + list(results.columns)]\n",
    "                               for model, results in x.items()],axis = 0), [train_results_dfs, test_results_dfs])\n",
    "\n",
    "network_name = 'Fresno'\n",
    "\n",
    "train_filename = f\"{datetime.now().strftime('%y%m%d%H%M%S')}_train_results_{network_name}.csv\"\n",
    "test_filename = f\"{datetime.now().strftime('%y%m%d%H%M%S')}_validation_results_{network_name}.csv\"\n",
    "train_results_df.to_csv(f\"./output/tables/{train_filename}\")\n",
    "print(f'File {train_filename} was written')\n",
    "test_results_df.to_csv(f\"./output/tables/{test_filename}\")\n",
    "print(f'File {test_filename} was written')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of models parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "models = [lue,odlue,odlulpe, tvodlulpe]\n",
    "results = pd.DataFrame({'parameter': [], 'model': []})\n",
    "\n",
    "for model in models:\n",
    "    results = results.append(pd.DataFrame(\n",
    "        {'parameter': ['tt'] + features_Z +\n",
    "                      ['rr'] +\n",
    "                      ['fixed_effect_mean', 'fixed_effect_std',\n",
    "                       'alpha_mean', 'alpha_std',\n",
    "                       'beta_mean', 'beta_std',\n",
    "                       'od_mean', 'od_std',],\n",
    "         'values': list(np.mean(model.theta.numpy(),axis =0))  +\n",
    "                   [float(model.get_parameters_estimates().eval('tt_sd/tt'))] +\n",
    "                   [np.mean(model.fixed_effect),np.std(model.fixed_effect),\n",
    "                    np.mean(model.alpha),np.std(model.alpha),\n",
    "                    np.mean(model.beta),np.std(model.beta),\n",
    "                    np.mean(model.q),np.std(model.q)]}).\\\n",
    "                             assign(model = model.key)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "results.pivot_table(index = ['parameter'], columns = 'model', values = 'values', sort=False).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_losses = pd.DataFrame({})\n",
    "loss_columns = ['loss_flow', 'loss_tt', 'loss_eq_flow', 'loss_total']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "\n",
    "    results_losses_model = model.split_results(train_results_dfs[model.key])[1].assign(model = model.key)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of models goodness of fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "results_losses = pd.DataFrame({})\n",
    "loss_columns = ['loss_flow', 'loss_tt', 'loss_eq_flow', 'loss_total']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "\n",
    "    results_losses_model = model.split_results(train_results_dfs[model.key])[1].assign(model = model.key)\n",
    "    results_losses_model = results_losses_model[results_losses_model.epoch == _EPOCHS['learning']].iloc[[0]]\n",
    "    results_losses = results_losses.append(results_losses_model)\n",
    "\n",
    "results_losses[loss_columns] = (results_losses[loss_columns]-1)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of convergence toward true rr across models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "models = [lue,odlue,odlulpe, tvodlulpe]\n",
    "\n",
    "train_estimates = {}\n",
    "train_losses = {}\n",
    "\n",
    "for model in models:\n",
    "    train_estimates[model.key], train_losses[model.key] = model.split_results(results=train_results_dfs[model.key])\n",
    "\n",
    "    train_estimates[model.key]['model'] = model.key\n",
    "\n",
    "train_estimates_df = pd.concat(train_estimates.values())\n",
    "\n",
    "train_estimates_df['rr'] = train_estimates_df['tt_sd']/train_estimates_df['tt']\n",
    "\n",
    "estimates = train_estimates_df[['epoch','model','rr']].reset_index().drop('index',axis = 1)\n",
    "estimates = estimates[estimates.epoch != 0]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "\n",
    "g = sns.lineplot(data=estimates, x='epoch', hue='model', y='rr')\n",
    "\n",
    "ax.set_ylabel('reliability ratio')\n",
    "\n",
    "plt.ylim(ymin=0)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gisuelogit-qeH6w6zX-py3.9",
   "language": "python",
   "name": "gisuelogit-qeh6w6zx-py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
