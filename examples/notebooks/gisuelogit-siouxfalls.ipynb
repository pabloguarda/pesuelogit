{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import isuelogit as isl\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main dir: /Users/pablo/Library/CloudStorage/OneDrive-Personal/data-science/github/gisuelogit\n"
     ]
    }
   ],
   "source": [
    "# Path management\n",
    "main_dir = str(Path(os.path.abspath('')).parents[1])\n",
    "os.chdir(main_dir)\n",
    "print('main dir:', main_dir)\n",
    "\n",
    "isl.config.dirs['read_network_data'] = \"input/network-data/fresno/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal modules\n",
    "from src.aesuelogit.visualizations import plot_predictive_performance, plot_heatmap_demands, plot_convergence_estimates\n",
    "from src.aesuelogit.models import UtilityParameters, GISUELOGIT, AETSUELOGIT, NGD, BPRParameters, ODParameters\n",
    "from src.aesuelogit.networks import load_k_shortest_paths, build_tntp_network, Equilibrator, ColumnGenerator\n",
    "from src.aesuelogit.etl import get_design_tensor, get_y_tensor, simulate_suelogit_data\n",
    "from src.aesuelogit.descriptive_statistics import mse, btcg_mse, mnrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed for reproducibility\n",
    "_SEED = 2022\n",
    "np.random.seed(_SEED)\n",
    "random.seed(_SEED)\n",
    "tf.random.set_seed(_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = 'SiouxFalls'\n",
    "tntp_network = build_tntp_network(network_name=network_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read OD matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Q from external file\n",
      "Matrix Q (24, 24) read in 0.4[s]                        \n",
      "\n",
      "360600.0 trips were loaded among 528 o-d pairs\n"
     ]
    }
   ],
   "source": [
    "Q = isl.reader.read_tntp_od(network_name=network_name)\n",
    "tntp_network.load_OD(Q=Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating at most 2 paths per od\n",
      "1056 paths were generated among 528 od pairs in 1.0 [s]\n",
      "\n",
      "1056 paths were loaded in the network\n",
      "Matrix D (76, 1056) generated in 1.3[s]               \n",
      "\n",
      "Matrix M (528, 1056) generated in 0.7[s]               \n",
      "\n",
      "Matrix C (1056, 1056) generated in 0.0[s]               \n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_k_shortest_paths(network=tntp_network, k=2, update_incidence_matrices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthethic data which was generated under the assumption of path sets of size 2.\n",
    "\n",
    "df = pd.read_csv(\n",
    "    main_dir + '/output/network-data/' + tntp_network.key + '/links/' + tntp_network.key + '-link-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_Z = ['c', 's']\n",
    "\n",
    "n_sparse_features = 0\n",
    "features_sparse = ['k' + str(i) for i in np.arange(0, n_sparse_features)]\n",
    "features_Z.extend(features_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 13:20:33.781095: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "n_days = len(df.period.unique())\n",
    "n_links = len(tntp_network.links)\n",
    "n_hours = 1\n",
    "\n",
    "# Add free flow travel times\n",
    "df['tt_ff'] = np.tile([link.bpr.tf for link in tntp_network.links], n_days)\n",
    "\n",
    "traveltime_data = get_design_tensor(y=df['traveltime'], n_links=n_links, n_days=n_days, n_hours=n_hours)\n",
    "flow_data = get_y_tensor(y=df[['counts']], n_links=n_links, n_days=n_days, n_hours=n_hours)\n",
    "\n",
    "Y = tf.concat([traveltime_data, flow_data], axis=3)\n",
    "X = get_design_tensor(Z=df[features_Z], n_links=n_links, n_days=n_days, n_hours=n_hours)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X.numpy(), Y.numpy(), test_size=0.2, random_state=_SEED)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = [tf.constant(i) for i in [X_train, X_test, Y_train, Y_test]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_EPOCHS = 2000\n",
    "_LR = 1e-1\n",
    "_RELATIVE_GAP = 1e-7\n",
    "_BATCH_SIZE = None\n",
    "_EPOCHS_PRINT_INTERVAL = 50\n",
    "\n",
    "loss_metric = mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_models = ['equilibrium','lue', 'ode', 'odlue', 'odlulpe']\n",
    "\n",
    "run_model = dict.fromkeys(list_models,True)\n",
    "# run_model = dict.fromkeys(list_models, False)\n",
    "\n",
    "# run_model['equilibrium'] = True\n",
    "# run_model['lue'] = True\n",
    "# run_model['ode'] = True\n",
    "# run_model['odlue'] = True\n",
    "# run_model['odlulpe'] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results_dfs = {}\n",
    "val_results_dfs = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Equilibrium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISUELOGIT: Equilibrium\n",
      "\n",
      "Epoch: 0, n_train: 80, n_test: 20\n",
      "\n",
      "0: train_loss=6.9e+07, val_loss=6.9e+07, train_loss tt=1e+04, val_loss tt=1e+04, train_loss flow=2.9e+07, val_loss flow=2.9e+07, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.71, relative gap=1e+10, train tt equilibrium loss=2.1e+04, train flow equilibrium loss=6.9e+07, time:  0.3\n",
      "\n",
      "Epoch: 50, n_train: 80, n_test: 20\n",
      "\n",
      "50: train_loss=4.3e+07, val_loss=4.3e+07, train_loss tt=2.7e+03, val_loss tt=2.8e+03, train_loss flow=1.7e+07, val_loss flow=1.7e+07, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.51, relative gap=-0.0013, train tt equilibrium loss=9.5e+03, train flow equilibrium loss=4.3e+07, time:  22.4\n",
      "\n",
      "Epoch: 100, n_train: 80, n_test: 20\n",
      "\n",
      "100: train_loss=3.2e+07, val_loss=3.2e+07, train_loss tt=1.7e+03, val_loss tt=1.7e+03, train_loss flow=1.3e+07, val_loss flow=1.3e+07, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.38, relative gap=-0.0017, train tt equilibrium loss=5.9e+03, train flow equilibrium loss=3.2e+07, time:  27.2\n",
      "\n",
      "Epoch: 150, n_train: 80, n_test: 20\n",
      "\n",
      "150: train_loss=2.5e+07, val_loss=2.5e+07, train_loss tt=1.3e+03, val_loss tt=1.3e+03, train_loss flow=1.1e+07, val_loss flow=1.1e+07, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.29, relative gap=-0.00044, train tt equilibrium loss=3.8e+03, train flow equilibrium loss=2.5e+07, time:  24.9\n",
      "\n",
      "Epoch: 200, n_train: 80, n_test: 20\n",
      "\n",
      "200: train_loss=2e+07, val_loss=2e+07, train_loss tt=1.1e+03, val_loss tt=1.1e+03, train_loss flow=9.7e+06, val_loss flow=9.8e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.22, relative gap=-0.00019, train tt equilibrium loss=2.7e+03, train flow equilibrium loss=2e+07, time:  27.4\n",
      "\n",
      "Epoch: 250, n_train: 80, n_test: 20\n",
      "\n",
      "250: train_loss=1.6e+07, val_loss=1.6e+07, train_loss tt=7.6e+02, val_loss tt=7.6e+02, train_loss flow=7.3e+06, val_loss flow=7.4e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.19, relative gap=-0.00026, train tt equilibrium loss=1.9e+03, train flow equilibrium loss=1.6e+07, time:  23.4\n",
      "\n",
      "Epoch: 300, n_train: 80, n_test: 20\n",
      "\n",
      "300: train_loss=1.2e+07, val_loss=1.2e+07, train_loss tt=3.2e+02, val_loss tt=3.2e+02, train_loss flow=6e+06, val_loss flow=6e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.14, relative gap=-0.00084, train tt equilibrium loss=1.1e+03, train flow equilibrium loss=1.2e+07, time:  21.4\n",
      "\n",
      "Epoch: 350, n_train: 80, n_test: 20\n",
      "\n",
      "350: train_loss=1e+07, val_loss=1e+07, train_loss tt=3.1e+02, val_loss tt=3.1e+02, train_loss flow=5.9e+06, val_loss flow=5.9e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.12, relative gap=-5.3e-06, train tt equilibrium loss=8.3e+02, train flow equilibrium loss=1e+07, time:  23.1\n",
      "\n",
      "Epoch: 400, n_train: 80, n_test: 20\n",
      "\n",
      "400: train_loss=9e+06, val_loss=9e+06, train_loss tt=3.1e+02, val_loss tt=3.1e+02, train_loss flow=5.8e+06, val_loss flow=5.8e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.11, relative gap=3.3e-06, train tt equilibrium loss=6.5e+02, train flow equilibrium loss=9e+06, time:  24.5\n",
      "\n",
      "Epoch: 450, n_train: 80, n_test: 20\n",
      "\n",
      "450: train_loss=7.9e+06, val_loss=7.9e+06, train_loss tt=3.1e+02, val_loss tt=3.1e+02, train_loss flow=5.7e+06, val_loss flow=5.7e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.095, relative gap=-5.5e-06, train tt equilibrium loss=5.2e+02, train flow equilibrium loss=7.9e+06, time:  24.9\n",
      "\n",
      "Epoch: 500, n_train: 80, n_test: 20\n",
      "\n",
      "500: train_loss=7e+06, val_loss=7e+06, train_loss tt=3.1e+02, val_loss tt=3.1e+02, train_loss flow=5.7e+06, val_loss flow=5.7e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.085, relative gap=-7.4e-06, train tt equilibrium loss=4.3e+02, train flow equilibrium loss=7e+06, time:  25.1\n",
      "\n",
      "Epoch: 550, n_train: 80, n_test: 20\n",
      "\n",
      "550: train_loss=6.2e+06, val_loss=6.2e+06, train_loss tt=3e+02, val_loss tt=3e+02, train_loss flow=5.6e+06, val_loss flow=5.6e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.076, relative gap=-0.00022, train tt equilibrium loss=3.5e+02, train flow equilibrium loss=6.2e+06, time:  21.7\n",
      "\n",
      "Epoch: 600, n_train: 80, n_test: 20\n",
      "\n",
      "600: train_loss=3.5e+06, val_loss=3.5e+06, train_loss tt=1.2e+02, val_loss tt=1.2e+02, train_loss flow=2.5e+06, val_loss flow=2.5e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.064, relative gap=-0.00023, train tt equilibrium loss=1.8e+02, train flow equilibrium loss=3.5e+06, time:  23.2\n",
      "\n",
      "Epoch: 650, n_train: 80, n_test: 20\n",
      "\n",
      "650: train_loss=3e+06, val_loss=3e+06, train_loss tt=1.1e+02, val_loss tt=1.1e+02, train_loss flow=2.4e+06, val_loss flow=2.4e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.056, relative gap=-7.2e-06, train tt equilibrium loss=1.5e+02, train flow equilibrium loss=3e+06, time:  26.3\n",
      "\n",
      "Epoch: 700, n_train: 80, n_test: 20\n",
      "\n",
      "700: train_loss=2.6e+06, val_loss=2.6e+06, train_loss tt=95, val_loss tt=95, train_loss flow=2.3e+06, val_loss flow=2.3e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.051, relative gap=-2.4e-05, train tt equilibrium loss=1.1e+02, train flow equilibrium loss=2.6e+06, time:  30.4\n",
      "\n",
      "Epoch: 750, n_train: 80, n_test: 20\n",
      "\n",
      "750: train_loss=2.1e+06, val_loss=2.1e+06, train_loss tt=80, val_loss tt=80, train_loss flow=2.1e+06, val_loss flow=2.1e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.046, relative gap=-0.0005, train tt equilibrium loss=86, train flow equilibrium loss=2.1e+06, time:  25.6\n",
      "\n",
      "Epoch: 800, n_train: 80, n_test: 20\n",
      "\n",
      "800: train_loss=1.7e+06, val_loss=1.7e+06, train_loss tt=79, val_loss tt=79, train_loss flow=2e+06, val_loss flow=2e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.041, relative gap=8.6e-07, train tt equilibrium loss=70, train flow equilibrium loss=1.7e+06, time:  23.8\n",
      "\n",
      "Epoch: 850, n_train: 80, n_test: 20\n",
      "\n",
      "850: train_loss=1.5e+06, val_loss=1.5e+06, train_loss tt=79, val_loss tt=79, train_loss flow=2e+06, val_loss flow=2e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.038, relative gap=-8.6e-06, train tt equilibrium loss=59, train flow equilibrium loss=1.5e+06, time:  24.5\n",
      "\n",
      "Epoch: 900, n_train: 80, n_test: 20\n",
      "\n",
      "900: train_loss=1.3e+06, val_loss=1.3e+06, train_loss tt=79, val_loss tt=79, train_loss flow=1.9e+06, val_loss flow=1.9e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.037, relative gap=-1.7e-05, train tt equilibrium loss=50, train flow equilibrium loss=1.3e+06, time:  24.5\n",
      "\n",
      "Epoch: 950, n_train: 80, n_test: 20\n",
      "\n",
      "950: train_loss=1e+06, val_loss=1e+06, train_loss tt=75, val_loss tt=76, train_loss flow=1.8e+06, val_loss flow=1.8e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.038, relative gap=-4.5e-05, train tt equilibrium loss=43, train flow equilibrium loss=1e+06, time:  26.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1000, n_train: 80, n_test: 20\n",
      "\n",
      "1000: train_loss=8.1e+05, val_loss=8.1e+05, train_loss tt=75, val_loss tt=75, train_loss flow=1.6e+06, val_loss flow=1.6e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.034, relative gap=-2.9e-05, train tt equilibrium loss=35, train flow equilibrium loss=8.1e+05, time:  22.1\n",
      "\n",
      "Epoch: 1050, n_train: 80, n_test: 20\n",
      "\n",
      "1050: train_loss=5.6e+05, val_loss=5.6e+05, train_loss tt=67, val_loss tt=66, train_loss flow=1.5e+06, val_loss flow=1.5e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.031, relative gap=-1.3e-05, train tt equilibrium loss=24, train flow equilibrium loss=5.6e+05, time:  22.2\n",
      "\n",
      "Epoch: 1100, n_train: 80, n_test: 20\n",
      "\n",
      "1100: train_loss=4.3e+05, val_loss=4.3e+05, train_loss tt=66, val_loss tt=66, train_loss flow=1.4e+06, val_loss flow=1.4e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.028, relative gap=-1.4e-05, train tt equilibrium loss=18, train flow equilibrium loss=4.3e+05, time:  21.7\n",
      "\n",
      "Epoch: 1150, n_train: 80, n_test: 20\n",
      "\n",
      "1150: train_loss=3.5e+05, val_loss=3.5e+05, train_loss tt=66, val_loss tt=66, train_loss flow=1.3e+06, val_loss flow=1.3e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.025, relative gap=-4.8e-06, train tt equilibrium loss=15, train flow equilibrium loss=3.5e+05, time:  21.5\n",
      "\n",
      "Epoch: 1200, n_train: 80, n_test: 20\n",
      "\n",
      "1200: train_loss=2.9e+05, val_loss=2.9e+05, train_loss tt=66, val_loss tt=66, train_loss flow=1.3e+06, val_loss flow=1.3e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.022, relative gap=-3e-06, train tt equilibrium loss=12, train flow equilibrium loss=2.9e+05, time:  25.0\n",
      "\n",
      "Epoch: 1250, n_train: 80, n_test: 20\n",
      "\n",
      "1250: train_loss=2.4e+05, val_loss=2.4e+05, train_loss tt=67, val_loss tt=67, train_loss flow=1.3e+06, val_loss flow=1.3e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.02, relative gap=-3e-06, train tt equilibrium loss=9.8, train flow equilibrium loss=2.4e+05, time:  24.1\n",
      "\n",
      "Epoch: 1300, n_train: 80, n_test: 20\n",
      "\n",
      "1300: train_loss=2e+05, val_loss=2e+05, train_loss tt=67, val_loss tt=67, train_loss flow=1.3e+06, val_loss flow=1.3e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.018, relative gap=-3e-06, train tt equilibrium loss=8, train flow equilibrium loss=2e+05, time:  21.9\n",
      "\n",
      "Epoch: 1350, n_train: 80, n_test: 20\n",
      "\n",
      "1350: train_loss=1.7e+05, val_loss=1.7e+05, train_loss tt=68, val_loss tt=67, train_loss flow=1.3e+06, val_loss flow=1.3e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.016, relative gap=-1.7e-06, train tt equilibrium loss=6.5, train flow equilibrium loss=1.7e+05, time:  22.2\n",
      "\n",
      "Epoch: 1400, n_train: 80, n_test: 20\n",
      "\n",
      "1400: train_loss=1.4e+05, val_loss=1.4e+05, train_loss tt=68, val_loss tt=68, train_loss flow=1.3e+06, val_loss flow=1.3e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.014, relative gap=-9.9e-07, train tt equilibrium loss=5.4, train flow equilibrium loss=1.4e+05, time:  24.4\n",
      "\n",
      "Epoch: 1450, n_train: 80, n_test: 20\n",
      "\n",
      "1450: train_loss=1.2e+05, val_loss=1.2e+05, train_loss tt=69, val_loss tt=68, train_loss flow=1.3e+06, val_loss flow=1.3e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.013, relative gap=-6.2e-07, train tt equilibrium loss=4.4, train flow equilibrium loss=1.2e+05, time:  22.6\n",
      "\n",
      "Epoch: 1500, n_train: 80, n_test: 20\n",
      "\n",
      "1500: train_loss=1e+05, val_loss=1e+05, train_loss tt=69, val_loss tt=69, train_loss flow=1.3e+06, val_loss flow=1.3e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.012, relative gap=-2.1e-07, train tt equilibrium loss=3.7, train flow equilibrium loss=1e+05, time:  21.8\n",
      "\n",
      "Epoch: 1523, n_train: 80, n_test: 20\n",
      "\n",
      "1523: train_loss=9.7e+04, val_loss=9.7e+04, train_loss tt=69, val_loss tt=69, train_loss flow=1.3e+06, val_loss flow=1.3e+06, theta = [-1. -6. -3.], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.011, relative gap=-3.3e-09, train tt equilibrium loss=3.4, train flow equilibrium loss=9.7e+04, time:  9.8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if run_model['equilibrium']:\n",
    "\n",
    "    _RELATIVE_GAP = 1e-8\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=_LR)\n",
    "\n",
    "    print('ISUELOGIT: Equilibrium')\n",
    "\n",
    "    utility_parameters = UtilityParameters(features_Y=['tt'],\n",
    "                                           features_Z=features_Z,\n",
    "                                           periods=1,\n",
    "                                           initial_values={'tt': -1, 'c': -6, 's': -3, 'psc_factor': 0,\n",
    "                                                           'fixed_effect': np.zeros_like(tntp_network.links)},\n",
    "                                           trainables={'psc_factor': False, 'fixed_effect': False\n",
    "                                               , 'tt': False, 'c': False, 's': False},\n",
    "                                           )\n",
    "\n",
    "    bpr_parameters = BPRParameters(keys=['alpha', 'beta'],\n",
    "                                   initial_values={'alpha': 0.15, 'beta': 4},\n",
    "                                   # initial_values={'alpha': 1, 'beta': 1},\n",
    "                                   trainables=dict.fromkeys(['alpha', 'beta'], False),\n",
    "                                   )\n",
    "\n",
    "    od_parameters = ODParameters(key='od',\n",
    "                                 periods=1,\n",
    "                                 # initial_values=0.6 * tntp_network.q.flatten(),\n",
    "                                 initial_values=tntp_network.q.flatten(),\n",
    "                                 true_values=tntp_network.q.flatten(),\n",
    "                                 historic_values={1: tntp_network.q.flatten()},\n",
    "                                 trainable=False)\n",
    "\n",
    "    len(tntp_network.q.flatten())\n",
    "\n",
    "    # q_historic = isl.networks.denseQ(isl.factory.random_disturbance_Q(tntp_network.Q, sd=np.mean(tntp_network.Q) * 0.05).copy())\n",
    "\n",
    "    q_historic = tntp_network.q\n",
    "\n",
    "    equilibrator = Equilibrator(\n",
    "        network=tntp_network,\n",
    "        # paths_generator=paths_generator,\n",
    "        utility=utility_parameters,\n",
    "        max_iters=100,\n",
    "        method='fw',\n",
    "        iters_fw=50,\n",
    "        accuracy=1e-4,\n",
    "    )\n",
    "\n",
    "    suelogit = GISUELOGIT(\n",
    "        key='suelogit',\n",
    "        # endogenous_flows=True,\n",
    "        network=tntp_network,\n",
    "        dtype=tf.float64,\n",
    "        equilibrator=equilibrator,\n",
    "        # column_generator=column_generator,\n",
    "        utility=utility_parameters,\n",
    "        bpr=bpr_parameters,\n",
    "        od=od_parameters\n",
    "    )\n",
    "\n",
    "    train_results_dfs['suelogit'], val_results_dfs['suelogit'] = suelogit.train(\n",
    "        X_train, Y_train, X_test, Y_test,\n",
    "        # generalization_error={'train': False, 'validation': True},\n",
    "        # loss_metric = mse,\n",
    "        loss_metric=loss_metric,\n",
    "        optimizer=optimizer,\n",
    "        batch_size=_BATCH_SIZE,\n",
    "        loss_weights={'od': 0, 'theta': 0, 'tt': 0, 'flow': 0, 'eq_flow': 1},\n",
    "        threshold_relative_gap=_RELATIVE_GAP,\n",
    "        epochs_print_interval = _EPOCHS_PRINT_INTERVAL,\n",
    "        epochs=_EPOCHS)\n",
    "\n",
    "    plot_predictive_performance(train_losses=train_results_dfs['suelogit'], val_losses=val_results_dfs['suelogit'],\n",
    "                                xticks_spacing= 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Benchmark of gisuelogit and isuelogit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LUE: Benchmark of aesuelogit and isuelogit (utility only)\n",
      "\n",
      "Epoch: 0, n_train: 80, n_test: 20\n",
      "\n",
      "0: train_loss=2.3e+07, val_loss=2.2e+07, train_loss tt=8.8e+03, val_loss tt=8.7e+03, train_loss flow=2.3e+07, val_loss flow=2.2e+07, theta = [0. 0. 0.], vot = nan, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=7.2e-17, relative gap=1e+10, train tt equilibrium loss=8.7e-28, train flow equilibrium loss=2.5e-24, time:  0.3\n",
      "\n",
      "Epoch: 50, n_train: 80, n_test: 20\n",
      "\n",
      "50: train_loss=4.3e+07, val_loss=4.3e+07, train_loss tt=7.1e+02, val_loss tt=7.1e+02, train_loss flow=1.4e+07, val_loss flow=1.4e+07, theta = [-0.5939 -0.9055 -0.7879], vot = 0.66, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.19, relative gap=0.00073, train tt equilibrium loss=4.8e+03, train flow equilibrium loss=2.9e+07, time:  23.4\n",
      "\n",
      "Epoch: 100, n_train: 80, n_test: 20\n",
      "\n",
      "100: train_loss=2.9e+07, val_loss=2.9e+07, train_loss tt=3.8e+02, val_loss tt=3.8e+02, train_loss flow=8.2e+06, val_loss flow=8.4e+06, theta = [-0.5941 -1.444  -1.1795], vot = 0.41, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.15, relative gap=0.0014, train tt equilibrium loss=3.1e+03, train flow equilibrium loss=2.1e+07, time:  24.4\n",
      "\n",
      "Epoch: 150, n_train: 80, n_test: 20\n",
      "\n",
      "150: train_loss=2.2e+07, val_loss=2.3e+07, train_loss tt=2e+02, val_loss tt=2e+02, train_loss flow=5.7e+06, val_loss flow=5.9e+06, theta = [-0.5926 -1.6313 -1.2326], vot = 0.36, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.14, relative gap=0.0001, train tt equilibrium loss=2.5e+03, train flow equilibrium loss=1.7e+07, time:  23.7\n",
      "\n",
      "Epoch: 200, n_train: 80, n_test: 20\n",
      "\n",
      "200: train_loss=1.8e+07, val_loss=1.8e+07, train_loss tt=1.1e+02, val_loss tt=1.1e+02, train_loss flow=4.1e+06, val_loss flow=4.2e+06, theta = [-0.5888 -1.9688 -1.3092], vot = 0.30, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.13, relative gap=0.00039, train tt equilibrium loss=2.1e+03, train flow equilibrium loss=1.4e+07, time:  22.5\n",
      "\n",
      "Epoch: 250, n_train: 80, n_test: 20\n",
      "\n",
      "250: train_loss=1.5e+07, val_loss=1.6e+07, train_loss tt=1.1e+02, val_loss tt=1.1e+02, train_loss flow=3.5e+06, val_loss flow=3.6e+06, theta = [-0.5843 -2.3349 -1.2705], vot = 0.25, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.11, relative gap=0.00033, train tt equilibrium loss=1.9e+03, train flow equilibrium loss=1.2e+07, time:  23.6\n",
      "\n",
      "Epoch: 300, n_train: 80, n_test: 20\n",
      "\n",
      "300: train_loss=1.4e+07, val_loss=1.4e+07, train_loss tt=1e+02, val_loss tt=1e+02, train_loss flow=3.4e+06, val_loss flow=3.5e+06, theta = [-0.5824 -2.5722 -1.2009], vot = 0.23, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.098, relative gap=9.3e-05, train tt equilibrium loss=1.6e+03, train flow equilibrium loss=1.1e+07, time:  23.2\n",
      "\n",
      "Epoch: 350, n_train: 80, n_test: 20\n",
      "\n",
      "350: train_loss=1.3e+07, val_loss=1.3e+07, train_loss tt=1e+02, val_loss tt=1e+02, train_loss flow=3.3e+06, val_loss flow=3.5e+06, theta = [-0.582  -2.6932 -1.1229], vot = 0.22, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.09, relative gap=8e-07, train tt equilibrium loss=1.4e+03, train flow equilibrium loss=9.4e+06, time:  22.7\n",
      "\n",
      "Epoch: 400, n_train: 80, n_test: 20\n",
      "\n",
      "400: train_loss=1.2e+07, val_loss=1.2e+07, train_loss tt=1.1e+02, val_loss tt=1.1e+02, train_loss flow=3.3e+06, val_loss flow=3.4e+06, theta = [-0.5811 -2.7886 -1.042 ], vot = 0.21, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.083, relative gap=-4.5e-05, train tt equilibrium loss=1.3e+03, train flow equilibrium loss=8.5e+06, time:  21.6\n",
      "\n",
      "Epoch: 450, n_train: 80, n_test: 20\n",
      "\n",
      "450: train_loss=1e+07, val_loss=1e+07, train_loss tt=93, val_loss tt=93, train_loss flow=2.7e+06, val_loss flow=2.8e+06, theta = [-0.5786 -2.8832 -0.9005], vot = 0.20, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.075, relative gap=-0.00036, train tt equilibrium loss=1.1e+03, train flow equilibrium loss=7.7e+06, time:  22.5\n",
      "\n",
      "Epoch: 500, n_train: 80, n_test: 20\n",
      "\n",
      "500: train_loss=9.6e+06, val_loss=9.7e+06, train_loss tt=93, val_loss tt=93, train_loss flow=2.7e+06, val_loss flow=2.7e+06, theta = [-0.578  -2.8786 -0.6763], vot = 0.20, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.073, relative gap=-0.00074, train tt equilibrium loss=9.7e+02, train flow equilibrium loss=7e+06, time:  21.8\n",
      "\n",
      "Epoch: 550, n_train: 80, n_test: 20\n",
      "\n",
      "550: train_loss=8.8e+06, val_loss=8.8e+06, train_loss tt=94, val_loss tt=93, train_loss flow=2.4e+06, val_loss flow=2.5e+06, theta = [-0.5783 -2.7653 -0.4767], vot = 0.21, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.076, relative gap=-0.00062, train tt equilibrium loss=8.4e+02, train flow equilibrium loss=6.4e+06, time:  22.8\n",
      "\n",
      "Epoch: 600, n_train: 80, n_test: 20\n",
      "\n",
      "600: train_loss=7.9e+06, val_loss=8e+06, train_loss tt=91, val_loss tt=90, train_loss flow=2.3e+06, val_loss flow=2.4e+06, theta = [-0.5789 -2.638  -0.3686], vot = 0.22, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.068, relative gap=-0.00036, train tt equilibrium loss=7.3e+02, train flow equilibrium loss=5.6e+06, time:  29.7\n",
      "\n",
      "Epoch: 650, n_train: 80, n_test: 20\n",
      "\n",
      "650: train_loss=7.3e+06, val_loss=7.4e+06, train_loss tt=92, val_loss tt=91, train_loss flow=2.3e+06, val_loss flow=2.3e+06, theta = [-0.5803 -2.6356 -0.2325], vot = 0.22, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.063, relative gap=-0.00019, train tt equilibrium loss=6.4e+02, train flow equilibrium loss=5.1e+06, time:  23.5\n",
      "\n",
      "Epoch: 700, n_train: 80, n_test: 20\n",
      "\n",
      "700: train_loss=6.9e+06, val_loss=6.9e+06, train_loss tt=92, val_loss tt=92, train_loss flow=2.2e+06, val_loss flow=2.3e+06, theta = [-0.5815 -2.6731 -0.1178], vot = 0.22, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.059, relative gap=-7.1e-05, train tt equilibrium loss=5.6e+02, train flow equilibrium loss=4.6e+06, time:  24.9\n",
      "\n",
      "Epoch: 750, n_train: 80, n_test: 20\n",
      "\n",
      "750: train_loss=6.4e+06, val_loss=6.5e+06, train_loss tt=93, val_loss tt=93, train_loss flow=2.2e+06, val_loss flow=2.3e+06, theta = [-0.5827 -2.7397 -0.0254], vot = 0.21, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.055, relative gap=1.1e-05, train tt equilibrium loss=4.9e+02, train flow equilibrium loss=4.2e+06, time:  22.3\n",
      "\n",
      "Epoch: 800, n_train: 80, n_test: 20\n",
      "\n",
      "800: train_loss=6.1e+06, val_loss=6.1e+06, train_loss tt=93, val_loss tt=93, train_loss flow=2.2e+06, val_loss flow=2.3e+06, theta = [-0.5837 -2.8254  0.0449], vot = 0.21, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.052, relative gap=8e-05, train tt equilibrium loss=4.2e+02, train flow equilibrium loss=3.8e+06, time:  26.8\n",
      "\n",
      "Epoch: 850, n_train: 80, n_test: 20\n",
      "\n",
      "850: train_loss=5.4e+06, val_loss=5.5e+06, train_loss tt=81, val_loss tt=81, train_loss flow=2e+06, val_loss flow=2e+06, theta = [-0.5841 -2.9878  0.0391], vot = 0.20, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.055, relative gap=-6.8e-06, train tt equilibrium loss=3.7e+02, train flow equilibrium loss=3.4e+06, time:  25.8\n",
      "\n",
      "Epoch: 900, n_train: 80, n_test: 20\n",
      "\n",
      "900: train_loss=4.7e+06, val_loss=4.7e+06, train_loss tt=65, val_loss tt=65, train_loss flow=1.8e+06, val_loss flow=1.8e+06, theta = [-0.5815 -3.1784  0.0286], vot = 0.18, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.056, relative gap=0.0013, train tt equilibrium loss=3.4e+02, train flow equilibrium loss=2.9e+06, time:  24.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 950, n_train: 80, n_test: 20\n",
      "\n",
      "950: train_loss=4.3e+06, val_loss=4.3e+06, train_loss tt=65, val_loss tt=65, train_loss flow=1.7e+06, val_loss flow=1.7e+06, theta = [-0.5811 -3.2868 -0.1425], vot = 0.18, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.048, relative gap=0.0002, train tt equilibrium loss=2.9e+02, train flow equilibrium loss=2.6e+06, time:  24.6\n",
      "\n",
      "Epoch: 1000, n_train: 80, n_test: 20\n",
      "\n",
      "1000: train_loss=3.8e+06, val_loss=3.8e+06, train_loss tt=63, val_loss tt=63, train_loss flow=1.6e+06, val_loss flow=1.6e+06, theta = [-0.5794 -3.4499 -0.3289], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.046, relative gap=0.00015, train tt equilibrium loss=2.6e+02, train flow equilibrium loss=2.2e+06, time:  23.2\n",
      "\n",
      "Epoch: 1050, n_train: 80, n_test: 20\n",
      "\n",
      "1050: train_loss=3.5e+06, val_loss=3.6e+06, train_loss tt=63, val_loss tt=63, train_loss flow=1.6e+06, val_loss flow=1.6e+06, theta = [-0.5798 -3.4573 -0.3257], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.042, relative gap=-8.2e-05, train tt equilibrium loss=2.2e+02, train flow equilibrium loss=2e+06, time:  22.2\n",
      "\n",
      "Epoch: 1100, n_train: 80, n_test: 20\n",
      "\n",
      "1100: train_loss=3.3e+06, val_loss=3.4e+06, train_loss tt=63, val_loss tt=63, train_loss flow=1.6e+06, val_loss flow=1.6e+06, theta = [-0.5803 -3.4484 -0.2884], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.04, relative gap=-6.1e-05, train tt equilibrium loss=1.9e+02, train flow equilibrium loss=1.8e+06, time:  23.9\n",
      "\n",
      "Epoch: 1150, n_train: 80, n_test: 20\n",
      "\n",
      "1150: train_loss=3.1e+06, val_loss=3.2e+06, train_loss tt=63, val_loss tt=63, train_loss flow=1.6e+06, val_loss flow=1.6e+06, theta = [-0.5802 -3.4406 -0.2671], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.038, relative gap=-4e-05, train tt equilibrium loss=1.6e+02, train flow equilibrium loss=1.6e+06, time:  22.3\n",
      "\n",
      "Epoch: 1200, n_train: 80, n_test: 20\n",
      "\n",
      "1200: train_loss=3e+06, val_loss=3e+06, train_loss tt=63, val_loss tt=63, train_loss flow=1.6e+06, val_loss flow=1.6e+06, theta = [-0.5795 -3.4282 -0.2565], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.036, relative gap=-5.5e-05, train tt equilibrium loss=1.3e+02, train flow equilibrium loss=1.4e+06, time:  23.6\n",
      "\n",
      "Epoch: 1250, n_train: 80, n_test: 20\n",
      "\n",
      "1250: train_loss=2.8e+06, val_loss=2.8e+06, train_loss tt=63, val_loss tt=63, train_loss flow=1.6e+06, val_loss flow=1.6e+06, theta = [-0.5774 -3.4072 -0.2399], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.035, relative gap=-8.6e-05, train tt equilibrium loss=1.1e+02, train flow equilibrium loss=1.2e+06, time:  22.3\n",
      "\n",
      "Epoch: 1300, n_train: 80, n_test: 20\n",
      "\n",
      "1300: train_loss=2.6e+06, val_loss=2.6e+06, train_loss tt=64, val_loss tt=64, train_loss flow=1.5e+06, val_loss flow=1.5e+06, theta = [-0.5705 -3.4499 -0.2264], vot = 0.17, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.035, relative gap=1.9e-05, train tt equilibrium loss=92, train flow equilibrium loss=1.1e+06, time:  22.4\n",
      "\n",
      "Epoch: 1350, n_train: 80, n_test: 20\n",
      "\n",
      "1350: train_loss=2.4e+06, val_loss=2.4e+06, train_loss tt=64, val_loss tt=64, train_loss flow=1.5e+06, val_loss flow=1.5e+06, theta = [-0.5644 -3.5848 -0.2178], vot = 0.16, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.033, relative gap=0.0001, train tt equilibrium loss=76, train flow equilibrium loss=9.3e+05, time:  27.1\n",
      "\n",
      "Epoch: 1400, n_train: 80, n_test: 20\n",
      "\n",
      "1400: train_loss=2.2e+06, val_loss=2.2e+06, train_loss tt=64, val_loss tt=64, train_loss flow=1.4e+06, val_loss flow=1.4e+06, theta = [-0.5595 -3.7121 -0.1783], vot = 0.15, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.032, relative gap=0.00011, train tt equilibrium loss=61, train flow equilibrium loss=7.9e+05, time:  28.9\n",
      "\n",
      "Epoch: 1450, n_train: 80, n_test: 20\n",
      "\n",
      "1450: train_loss=2.1e+06, val_loss=2.1e+06, train_loss tt=65, val_loss tt=64, train_loss flow=1.4e+06, val_loss flow=1.4e+06, theta = [-0.5571 -3.8405 -0.1515], vot = 0.15, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.029, relative gap=0.00021, train tt equilibrium loss=50, train flow equilibrium loss=6.6e+05, time:  32.9\n",
      "\n",
      "Epoch: 1500, n_train: 80, n_test: 20\n",
      "\n",
      "1500: train_loss=1.9e+06, val_loss=1.9e+06, train_loss tt=65, val_loss tt=65, train_loss flow=1.4e+06, val_loss flow=1.4e+06, theta = [-0.5549 -3.9967 -0.1501], vot = 0.14, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.028, relative gap=0.0002, train tt equilibrium loss=40, train flow equilibrium loss=5.5e+05, time:  26.7\n",
      "\n",
      "Epoch: 1550, n_train: 80, n_test: 20\n",
      "\n",
      "1550: train_loss=1.8e+06, val_loss=1.8e+06, train_loss tt=65, val_loss tt=65, train_loss flow=1.4e+06, val_loss flow=1.4e+06, theta = [-0.552  -4.1248 -0.1339], vot = 0.13, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.025, relative gap=0.00019, train tt equilibrium loss=31, train flow equilibrium loss=4.6e+05, time:  25.1\n",
      "\n",
      "Epoch: 1600, n_train: 80, n_test: 20\n",
      "\n",
      "1600: train_loss=1.7e+06, val_loss=1.7e+06, train_loss tt=66, val_loss tt=66, train_loss flow=1.3e+06, val_loss flow=1.3e+06, theta = [-0.5465 -4.3387 -0.1166], vot = 0.13, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.024, relative gap=0.0003, train tt equilibrium loss=22, train flow equilibrium loss=3.6e+05, time:  26.8\n",
      "\n",
      "Epoch: 1650, n_train: 80, n_test: 20\n",
      "\n",
      "1650: train_loss=1.6e+06, val_loss=1.6e+06, train_loss tt=67, val_loss tt=66, train_loss flow=1.3e+06, val_loss flow=1.3e+06, theta = [-0.5426 -4.4988 -0.1223], vot = 0.12, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.022, relative gap=0.00018, train tt equilibrium loss=16, train flow equilibrium loss=2.8e+05, time:  28.7\n",
      "\n",
      "Epoch: 1700, n_train: 80, n_test: 20\n",
      "\n",
      "1700: train_loss=1.5e+06, val_loss=1.5e+06, train_loss tt=67, val_loss tt=67, train_loss flow=1.3e+06, val_loss flow=1.3e+06, theta = [-0.5403 -4.5723 -0.1397], vot = 0.12, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.019, relative gap=7.5e-05, train tt equilibrium loss=12, train flow equilibrium loss=2.2e+05, time:  25.4\n",
      "\n",
      "Epoch: 1750, n_train: 80, n_test: 20\n",
      "\n",
      "1750: train_loss=1.4e+06, val_loss=1.4e+06, train_loss tt=68, val_loss tt=67, train_loss flow=1.3e+06, val_loss flow=1.3e+06, theta = [-0.5399 -4.5566 -0.1829], vot = 0.12, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.017, relative gap=-2.1e-06, train tt equilibrium loss=8.5, train flow equilibrium loss=1.7e+05, time:  27.0\n",
      "\n",
      "Epoch: 1800, n_train: 80, n_test: 20\n",
      "\n",
      "1800: train_loss=1.4e+06, val_loss=1.4e+06, train_loss tt=68, val_loss tt=68, train_loss flow=1.3e+06, val_loss flow=1.3e+06, theta = [-0.5406 -4.4837 -0.2495], vot = 0.12, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.015, relative gap=-2.3e-05, train tt equilibrium loss=6.5, train flow equilibrium loss=1.3e+05, time:  25.8\n",
      "\n",
      "Epoch: 1850, n_train: 80, n_test: 20\n",
      "\n",
      "1850: train_loss=1.4e+06, val_loss=1.4e+06, train_loss tt=68, val_loss tt=68, train_loss flow=1.3e+06, val_loss flow=1.3e+06, theta = [-0.5419 -4.3906 -0.3329], vot = 0.12, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.014, relative gap=-1.5e-05, train tt equilibrium loss=5.1, train flow equilibrium loss=1.1e+05, time:  25.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1900, n_train: 80, n_test: 20\n",
      "\n",
      "1900: train_loss=1.3e+06, val_loss=1.3e+06, train_loss tt=68, val_loss tt=68, train_loss flow=1.3e+06, val_loss flow=1.3e+06, theta = [-0.5433 -4.2946 -0.4258], vot = 0.13, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.013, relative gap=-1.9e-06, train tt equilibrium loss=4, train flow equilibrium loss=8.8e+04, time:  23.6\n",
      "\n",
      "Epoch: 1950, n_train: 80, n_test: 20\n",
      "\n",
      "1950: train_loss=1.3e+06, val_loss=1.3e+06, train_loss tt=68, val_loss tt=68, train_loss flow=1.3e+06, val_loss flow=1.3e+06, theta = [-0.5449 -4.2024 -0.5229], vot = 0.13, psc_factor = 0.0, avg abs theta fixed effect = 0, avg alpha=0.15, avg beta=4, loss demand=1.3e-26, relative x=0.012, relative gap=1.1e-05, train tt equilibrium loss=3.2, train flow equilibrium loss=7.2e+04, time:  25.7\n"
     ]
    }
   ],
   "source": [
    "if run_model['lue']:\n",
    "    print('\\nLUE: Benchmark of aesuelogit and isuelogit (utility only)')\n",
    "\n",
    "    # optimizer = NGD(learning_rate=_LR)\n",
    "    # optimizer = tf.keras.optimizers.SGD(learning_rate=_LR)\n",
    "\n",
    "    # Initialize again the optimizer as there are some decay parameters that are stored in the object and that will\n",
    "    # affect the next model estimation\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=_LR)\n",
    "\n",
    "    _RELATIVE_GAP = 1e-8\n",
    "\n",
    "    utility_parameters = UtilityParameters(features_Y=['tt'],\n",
    "                                           features_Z=features_Z,\n",
    "                                           periods=1,\n",
    "                                           initial_values={'tt': 0, 'c': 0, 's': 0, 'psc_factor': 0,\n",
    "                                                           'fixed_effect': np.zeros_like(tntp_network.links)},\n",
    "                                           true_values={'tt': -1, 'c': -6, 's': -3},\n",
    "                                           trainables={'psc_factor': False, 'fixed_effect': False\n",
    "                                               , 'tt': True, 'c': True, 's': True},\n",
    "                                           )\n",
    "\n",
    "    # utility_parameters.random_initializer((-1,1),['tt','c','s'])\n",
    "    # utility_parameters.random_initializer((0, 0), ['tt', 'c', 's'])\n",
    "\n",
    "    bpr_parameters = BPRParameters(keys=['alpha', 'beta'],\n",
    "                                   initial_values={'alpha': 0.15, 'beta': 4},\n",
    "                                   # initial_values={'alpha': 1, 'beta': 1},\n",
    "                                   trainables=dict.fromkeys(['alpha', 'beta'], False))\n",
    "\n",
    "    # q_historic = isl.networks.denseQ(isl.factory.random_disturbance_Q(tntp_network.Q, sd=np.mean(tntp_network.Q) * 0.1).copy())\n",
    "\n",
    "    q_historic = tntp_network.q\n",
    "\n",
    "    od_parameters = ODParameters(key='od',\n",
    "                                 periods=1,\n",
    "                                 # initial_values=0.6 * tntp_network.q.flatten(),\n",
    "                                 # initial_values=tntp_network.q.flatten(),\n",
    "                                 # true_values=tntp_network.q.flatten(),\n",
    "                                 initial_values=q_historic.flatten(),\n",
    "                                 historic_values={1: q_historic.flatten()},\n",
    "                                 # historic_values={1: tntp_network.q.flatten()},\n",
    "                                 trainable=False)\n",
    "\n",
    "    equilibrator = Equilibrator(\n",
    "        network=tntp_network,\n",
    "        # paths_generator=paths_generator,\n",
    "        utility=utility_parameters,\n",
    "        max_iters=100,\n",
    "        method='fw',\n",
    "        iters_fw=50,\n",
    "        accuracy=1e-4,\n",
    "    )\n",
    "\n",
    "    lue = GISUELOGIT(\n",
    "        key='lue',\n",
    "        # endogenous_flows=True,\n",
    "        network=tntp_network,\n",
    "        dtype=tf.float64,\n",
    "        equilibrator=equilibrator,\n",
    "        # column_generator=column_generator,\n",
    "        utility=utility_parameters,\n",
    "        bpr=bpr_parameters,\n",
    "        od=od_parameters\n",
    "    )\n",
    "\n",
    "    train_results_dfs['lue'], val_results_dfs['lue'] = lue.train(\n",
    "        X_train, Y_train, X_test, Y_test,\n",
    "        # generalization_error={'train': False, 'validation': True},\n",
    "        optimizer=optimizer,\n",
    "        batch_size=_BATCH_SIZE,\n",
    "        loss_metric=loss_metric,\n",
    "        loss_weights={'od': 0, 'theta': 0, 'tt': 1, 'flow': 1, 'eq_flow': 1},\n",
    "        threshold_relative_gap=_RELATIVE_GAP,\n",
    "        epochs_print_interval=_EPOCHS_PRINT_INTERVAL,\n",
    "        epochs=_EPOCHS)\n",
    "\n",
    "    plot_predictive_performance(train_losses=train_results_dfs['lue'], val_losses=val_results_dfs['lue'],\n",
    "                                xticks_spacing= 250)\n",
    "\n",
    "    print(f\"theta = {dict(zip(utility_parameters.true_values.keys(), list(lue.theta.numpy())))}\")\n",
    "    print(f\"alpha = {lue.alpha: 0.2f}, beta  = {lue.beta: 0.2f}\")\n",
    "    print(f\"Avg abs diff of observed and estimated OD: {np.mean(np.abs(lue.q - tntp_network.q.flatten())): 0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: OD + utility estimation with historic OD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_model['ode']:\n",
    "    print('\\n ODE: OD estimation with historic OD')\n",
    "\n",
    "    _RELATIVE_GAP = 1e-8\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=_LR)\n",
    "    # optimizer = tf.keras.optimizers.Adagrad(learning_rate=_LR)\n",
    "\n",
    "    utility_parameters = UtilityParameters(features_Y=['tt'],\n",
    "                                           features_Z=features_Z,\n",
    "                                           periods=1,\n",
    "                                           initial_values={'tt': -1, 'c': -6, 's': -3, 'psc_factor': 0,\n",
    "                                                           'fixed_effect': np.zeros_like(tntp_network.links)},\n",
    "                                           trainables={'psc_factor': False, 'fixed_effect': False\n",
    "                                               , 'tt': False, 'c': False, 's': False},\n",
    "                                           )\n",
    "\n",
    "    bpr_parameters = BPRParameters(keys=['alpha', 'beta'],\n",
    "                                   initial_values={'alpha': 0.15, 'beta': 4},\n",
    "                                   trainables=dict.fromkeys(['alpha', 'beta'], False),\n",
    "                                   )\n",
    "\n",
    "    Q_historic = isl.factory.random_disturbance_Q(tntp_network.Q, sd=np.mean(tntp_network.Q) * 0.1).copy()\n",
    "\n",
    "    od_parameters = ODParameters(key='od',\n",
    "                                 periods=1,\n",
    "                                 # initial_values=tntp_network.q.flatten(),\n",
    "                                 initial_values= isl.networks.denseQ(Q_historic).flatten(),\n",
    "                                 # initial_values=np.ones_like(tntp_network.q.flatten()),\n",
    "                                 historic_values={1: isl.networks.denseQ(Q_historic).flatten()},\n",
    "                                 trainable=True)\n",
    "\n",
    "    equilibrator = Equilibrator(\n",
    "        network=tntp_network,\n",
    "        # paths_generator=paths_generator,\n",
    "        utility=utility_parameters,\n",
    "        max_iters=100,\n",
    "        method='fw',\n",
    "        iters_fw=50,\n",
    "        accuracy=1e-4,\n",
    "    )\n",
    "\n",
    "    ode = GISUELOGIT(\n",
    "        key='ode',\n",
    "        network=tntp_network,\n",
    "        dtype=tf.float64,\n",
    "        equilibrator=equilibrator,\n",
    "        utility=utility_parameters,\n",
    "        bpr=bpr_parameters,\n",
    "        od=od_parameters,\n",
    "    )\n",
    "\n",
    "    train_results_dfs['ode'], val_results_dfs['ode'] = ode.train(\n",
    "        X_train, Y_train, X_test, Y_test,\n",
    "        optimizer=optimizer,\n",
    "        batch_size=_BATCH_SIZE,\n",
    "        loss_metric=loss_metric,\n",
    "        # generalization_error={'train': False, 'validation': True},\n",
    "        loss_weights={'od': 1, 'theta': 0, 'tt': 1, 'flow': 1, 'eq_flow': 1},\n",
    "        threshold_relative_gap=_RELATIVE_GAP,\n",
    "        epochs_print_interval=_EPOCHS_PRINT_INTERVAL,\n",
    "        epochs=_EPOCHS)\n",
    "\n",
    "    plot_predictive_performance(train_losses=train_results_dfs['ode'], val_losses=val_results_dfs['ode'],\n",
    "                                xticks_spacing= 250)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    Qs = {'true': tntp_network.OD.Q_true, 'historic': Q_historic, 'estimated': tf.sparse.to_dense(ode.Q).numpy()}\n",
    "\n",
    "    plot_heatmap_demands(Qs=Qs, vmin=np.min(Qs['true']), vmax=np.max(Qs['true']), subplots_dims=(1, 3), figsize=(12, 4))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"theta = {dict(zip(utility_parameters.true_values.keys(), list(ode.theta.numpy())))}\")\n",
    "    print(f\"alpha = {ode.alpha: 0.2f}, beta  = {ode.beta: 0.2f}\")\n",
    "    print(f\"Avg abs diff of observed and estimated OD: {np.mean(np.abs(ode.q - tntp_network.q.flatten())): 0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: OD + utility estimation with historic OD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_model['odlue']:\n",
    "    print('\\nODLUE: OD + utility estimation with historic OD')\n",
    "\n",
    "    _RELATIVE_GAP = 1e-8\n",
    "\n",
    "    # optimizer = tf.keras.optimizers.Adagrad(learning_rate=_LR)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=_LR)\n",
    "\n",
    "    utility_parameters = UtilityParameters(features_Y=['tt'],\n",
    "                                           features_Z=features_Z,\n",
    "                                           periods=1,\n",
    "                                           initial_values={'tt': 0, 'c': 0, 's': 0, 'psc_factor': 0,\n",
    "                                                           'fixed_effect': np.zeros_like(tntp_network.links)},\n",
    "                                           true_values={'tt': -1, 'c': -6, 's': -3},\n",
    "                                           # signs={'tt': '-', 'c': '-', 's': '-'},\n",
    "                                           trainables={'psc_factor': False, 'fixed_effect': False\n",
    "                                               , 'tt': True, 'c': True, 's': True},\n",
    "                                           )\n",
    "\n",
    "    # utility_parameters.random_initializer((-1,1),['tt','c','s'])\n",
    "\n",
    "    bpr_parameters = BPRParameters(keys=['alpha', 'beta'],\n",
    "                                   initial_values={'alpha': 0.15, 'beta': 4},\n",
    "                                   trainables=dict.fromkeys(['alpha', 'beta'], False),\n",
    "                                   )\n",
    "\n",
    "    Q_historic = isl.factory.random_disturbance_Q(tntp_network.Q, sd=np.mean(tntp_network.Q) * 0.1).copy()\n",
    "\n",
    "    od_parameters = ODParameters(key='od',\n",
    "                                 periods=1,\n",
    "                                 # initial_values=tntp_network.q.flatten(),\n",
    "                                 initial_values= isl.networks.denseQ(Q_historic).flatten(),\n",
    "                                 # initial_values=np.ones_like(tntp_network.q.flatten()),\n",
    "                                 historic_values={1: isl.networks.denseQ(Q_historic).flatten()},\n",
    "                                 # historic_values={1: tntp_network.q.flatten()},\n",
    "                                 trainable=True)\n",
    "\n",
    "    equilibrator = Equilibrator(\n",
    "        network=tntp_network,\n",
    "        # paths_generator=paths_generator,\n",
    "        utility=utility_parameters,\n",
    "        max_iters=100,\n",
    "        method='fw',\n",
    "        iters_fw=50,\n",
    "        accuracy=1e-4,\n",
    "    )\n",
    "\n",
    "    odlue = GISUELOGIT(\n",
    "        key='odlue',\n",
    "        network=tntp_network,\n",
    "        dtype=tf.float64,\n",
    "        equilibrator=equilibrator,\n",
    "        utility=utility_parameters,\n",
    "        bpr=bpr_parameters,\n",
    "        od=od_parameters,\n",
    "    )\n",
    "\n",
    "    train_results_dfs['odlue'], val_results_dfs['odlue'] = odlue.train(\n",
    "        X_train, Y_train, X_test, Y_test,\n",
    "        optimizer=optimizer,\n",
    "        batch_size=_BATCH_SIZE,\n",
    "        loss_metric=loss_metric,\n",
    "        # loss_metric=mse,\n",
    "        # generalization_error={'train': False, 'validation': True},\n",
    "        loss_weights={'od': 1, 'theta': 0, 'tt': 1, 'flow': 1, 'eq_flow': 1},\n",
    "        threshold_relative_gap=_RELATIVE_GAP,\n",
    "        epochs_print_interval=_EPOCHS_PRINT_INTERVAL,\n",
    "        epochs=_EPOCHS)\n",
    "\n",
    "    plot_predictive_performance(train_losses=train_results_dfs['odlue'], val_losses=val_results_dfs['odlue'],\n",
    "                                xticks_spacing= 250)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    Qs = {'true': tntp_network.OD.Q_true, 'historic': Q_historic, 'estimated': tf.sparse.to_dense(odlue.Q).numpy()}\n",
    "\n",
    "    plot_heatmap_demands(Qs=Qs, vmin=np.min(Qs['true']), vmax=np.max(Qs['true']), subplots_dims=(1, 3), figsize=(12, 4))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"theta = {dict(zip(utility_parameters.true_values.keys(), list(odlue.theta.numpy())))}\")\n",
    "    print(f\"alpha = {odlue.alpha: 0.2f}, beta  = {odlue.beta: 0.2f}\")\n",
    "    print(f\"Avg abs diff of observed and estimated OD: {np.mean(np.abs(odlue.q - tntp_network.q.flatten())): 0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5: ODLUE + link specific performance parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_model['odlulpe']:\n",
    "    _RELATIVE_GAP = 1e-8\n",
    "\n",
    "    print('\\nODLULPE: ODLUE + link performance parameters with historic OD matrix')\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=_LR)\n",
    "\n",
    "    bpr_parameters = BPRParameters(keys=['alpha', 'beta'],\n",
    "                                   initial_values={'alpha': 0.15, 'beta': 4},\n",
    "                                   # initial_values={'alpha': 1, 'beta': 1},\n",
    "                                   # initial_values={'alpha': np.ones_like(tntp_network.links, dtype=np.float32),\n",
    "                                   #                 'beta': 4 * np.ones_like(tntp_network.links, dtype=np.float32)},\n",
    "                                   true_values={'alpha': 0.15, 'beta': 4},\n",
    "                                   # initial_values={'alpha': 0.15, 'beta': 4},\n",
    "                                   trainables={'alpha': True, 'beta':True},\n",
    "                                   )\n",
    "\n",
    "    # bpr_parameters.random_initializer((-1,1),['beta'])\n",
    "    # bpr_parameters.random_initializer((-0.15, 0.15), ['alpha'])\n",
    "\n",
    "    Q_historic = isl.factory.random_disturbance_Q(tntp_network.Q, sd=np.mean(tntp_network.Q) * 0.1).copy()\n",
    "\n",
    "    od_parameters = ODParameters(key='od',\n",
    "                                 periods=1,\n",
    "                                 # initial_values=tntp_network.q.flatten(),\n",
    "                                 initial_values=isl.networks.denseQ(Q_historic).flatten(),\n",
    "                                 # initial_values=np.ones_like(tntp_network.q.flatten()),\n",
    "                                 historic_values={1: isl.networks.denseQ(Q_historic).flatten()},\n",
    "                                 # historic_values={1: tntp_network.q.flatten()},\n",
    "                                 trainable=True)\n",
    "\n",
    "    utility_parameters = UtilityParameters(features_Y=['tt'],\n",
    "                                           features_Z=features_Z,\n",
    "                                           periods=1,\n",
    "                                           initial_values={'tt': 0, 'c': 0, 's': 0, 'psc_factor': 0,\n",
    "                                                           'fixed_effect': np.zeros_like(tntp_network.links)},\n",
    "                                           true_values={'tt': -1, 'c': -6, 's': -3},\n",
    "                                           # signs={'tt': '-', 'c': '-', 's': '-'},\n",
    "                                           trainables={'psc_factor': False, 'fixed_effect': False\n",
    "                                               , 'tt': True, 'c': True, 's': True},\n",
    "                                           )\n",
    "\n",
    "    # utility_parameters.random_initializer((-1,1),['tt','c','s'])\n",
    "\n",
    "    equilibrator = Equilibrator(\n",
    "        network=tntp_network,\n",
    "        # paths_generator=paths_generator,\n",
    "        utility=utility_parameters,\n",
    "        max_iters=100,\n",
    "        method='fw',\n",
    "        iters_fw=50,\n",
    "        accuracy=1e-4,\n",
    "    )\n",
    "\n",
    "    odlulpe = GISUELOGIT(\n",
    "        key='odlulpe',\n",
    "        network=tntp_network,\n",
    "        dtype=tf.float64,\n",
    "        equilibrator=equilibrator,\n",
    "        utility=utility_parameters,\n",
    "        bpr=bpr_parameters,\n",
    "        od=od_parameters,\n",
    "    )\n",
    "\n",
    "    train_results_dfs['odlulpe'], val_results_dfs['odlulpe'] = odlulpe.train(\n",
    "        X_train, Y_train, X_test, Y_test,\n",
    "        optimizer=optimizer,\n",
    "        # generalization_error={'train': False, 'validation': True},\n",
    "        batch_size=_BATCH_SIZE,\n",
    "        loss_weights={'od': 1, 'theta': 0, 'tt': 1, 'flow': 1, 'eq_flow': 1},\n",
    "        loss_metric=loss_metric,\n",
    "        threshold_relative_gap=_RELATIVE_GAP,\n",
    "        epochs_print_interval=_EPOCHS_PRINT_INTERVAL,\n",
    "        epochs=_EPOCHS)\n",
    "\n",
    "    plot_predictive_performance(train_losses=train_results_dfs['odlulpe'], val_losses=val_results_dfs['odlulpe'],\n",
    "                                xticks_spacing = 250)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    Qs = {'true': tntp_network.OD.Q_true, 'historic': Q_historic, 'estimated': tf.sparse.to_dense(odlulpe.Q).numpy()}\n",
    "\n",
    "    plot_heatmap_demands(Qs=Qs, vmin=np.min(Qs['true']), vmax=np.max(Qs['true']), subplots_dims=(1, 3), figsize=(12, 4))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"theta = {dict(zip(utility_parameters.true_values.keys(), list(odlulpe.theta.numpy())))}\")\n",
    "    print(f\"alpha = {np.mean(odlulpe.alpha): 0.2f}, beta  = {np.mean(odlulpe.beta): 0.2f}\")\n",
    "    print(f\"Avg abs diff of observed and estimated OD: {np.mean(np.abs(odlulpe.q - tntp_network.q.flatten())): 0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of convergence toward true vot across models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [lue,odlue,odlulpe]\n",
    "\n",
    "train_estimates = {}\n",
    "train_losses = {}\n",
    "\n",
    "for model in models:\n",
    "    train_estimates[model.key], train_losses[model.key] = model.split_results(results=train_results_dfs[model.key])\n",
    "\n",
    "    train_estimates[model.key]['model'] = model.key\n",
    "\n",
    "train_estimates_df = pd.concat(train_estimates.values())\n",
    "\n",
    "train_estimates_df['vot'] = train_estimates_df['tt']/train_estimates_df['c']\n",
    "\n",
    "estimates = train_estimates_df[['epoch','model','vot']].reset_index().drop('index',axis = 1)\n",
    "estimates = estimates[estimates.epoch != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "\n",
    "g = sns.lineplot(data=estimates, x='epoch', hue='model', y='vot')\n",
    "\n",
    "ax.hlines(y=1/6, xmin=estimates['epoch'].min(), xmax=estimates['epoch'].max(), linestyle='--', label = 'truth')\n",
    "\n",
    "# ax.set_ylabel('value of time')\n",
    "\n",
    "plt.ylim(ymin=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aesuelogit-1kW0OCrg-py3.9",
   "language": "python",
   "name": "aesuelogit-1kw0ocrg-py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
