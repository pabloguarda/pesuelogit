{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "# import cudf as pd\n",
    "import tensorflow as tf\n",
    "import isuelogit as isl\n",
    "import glob\n",
    "\n",
    "from src.aesuelogit.models import UtilityFunction, AESUELOGIT, NGD\n",
    "from src.aesuelogit.visualizations import plot_predictive_performance\n",
    "from src.aesuelogit.networks import load_k_shortest_paths, read_paths, build_fresno_network, \\\n",
    "    Equilibrator, sparsify_OD, ColumnGenerator, read_OD\n",
    "\n",
    "from src.aesuelogit.etl import get_design_tensor, get_y_tensor, data_curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main dir: /Users/pablo/OneDrive/data-science/github/aesuelogit\n"
     ]
    }
   ],
   "source": [
    "# Path management\n",
    "main_dir = str(Path(os.path.abspath('')).parents[1])\n",
    "os.chdir(main_dir)\n",
    "print('main dir:', main_dir)\n",
    "\n",
    "isl.config.dirs['read_network_data'] = \"input/network-data/fresno/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Seed for reproducibility\n",
    "_SEED = 2022\n",
    "\n",
    "np.random.seed(_SEED)\n",
    "random.seed(_SEED)\n",
    "tf.random.set_seed(_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Build Fresno network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fresno_network = build_fresno_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Read OD matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Q (1789, 1789) read in 0.1[s] with sparse format\n",
      "66266.3 trips were loaded among 6970 o-d pairs\n"
     ]
    }
   ],
   "source": [
    "# TODO: specify path to read OD matrix\n",
    "read_OD(network=fresno_network, sparse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Read paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix D (2413, 18289) generated in 21.2[s]               \n",
      "\n",
      "Matrix M (6970, 18289) generated in 7.9[s]               \n",
      "\n",
      "Matrix C (18289, 18289) generated in 5.0[s]               \n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_paths(network=fresno_network, update_incidence_matrices=True, filename = 'paths-full-model-fresno.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Read spatiotemporal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "folderpath = isl.config.dirs['read_network_data'] + 'links/spatiotemporal-data/'\n",
    "df = pd.concat([pd.read_csv(file) for file in glob.glob(folderpath + \"*fresno-link-data*\")], axis=0)\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "df = df[df['date'].dt.dayofweek.between(0, 4)]\n",
    "# df = df[df['date'].dt.year == 2019]\n",
    "\n",
    "df['period'] = df['date'].astype(str) + '-' + df['hour'].astype(str)\n",
    "df['period'] = df.period.map(hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features_Z = ['speed_sd', 'median_inc', 'incidents', 'bus_stops', 'intersections']\n",
    "# features_Z = ['speed_sd']\n",
    "# features_Z = []\n",
    "\n",
    "utility_function = UtilityFunction(features_Y=['tt'],\n",
    "                                   features_Z=features_Z,\n",
    "                                   signs={'tt': '-', 'speed_sd': '-', 'median_inc': '+', 'incidents': '-',\n",
    "                                          'bus_stops': '-', 'intersections': '-'},\n",
    "                                   # initial_values={'tt': 0, 'median_inc': 0, 'incidents': 0}\n",
    "                                   )\n",
    "\n",
    "utility_function.constant_initializer(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['tt_avg'] = np.divide(df['length'],df['speed_hist_avg'],\n",
    "                         out=np.zeros_like(df['length']), where=df['speed_hist_avg']!=0)\n",
    "\n",
    "df['tt_ff'] = np.divide(df['length'],df['speed_ref_avg'],\n",
    "                         out=np.zeros_like(df['length']), where=df['speed_ref_avg']!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = data_curation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_links = len(fresno_network.links)\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "df['year'] = df.date.dt.year\n",
    "X, Y = {}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "      <th>tt_ff</th>\n",
       "      <th>tt_avg</th>\n",
       "      <th>tf_inrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9704.000000</td>\n",
       "      <td>166497.000000</td>\n",
       "      <td>166497.000000</td>\n",
       "      <td>166497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1880.469281</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>0.005273</td>\n",
       "      <td>0.192740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>791.369747</td>\n",
       "      <td>0.003330</td>\n",
       "      <td>0.005555</td>\n",
       "      <td>0.224399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1361.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1787.000000</td>\n",
       "      <td>0.003430</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2302.700000</td>\n",
       "      <td>0.004736</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>0.272000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4807.000000</td>\n",
       "      <td>0.038373</td>\n",
       "      <td>0.068856</td>\n",
       "      <td>4.605000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            counts          tt_ff         tt_avg       tf_inrix\n",
       "count  9704.000000  166497.000000  166497.000000  166497.000000\n",
       "mean   1880.469281       0.003396       0.005273       0.192740\n",
       "std     791.369747       0.003330       0.005555       0.224399\n",
       "min       3.000000       0.000000       0.000000       0.000000\n",
       "25%    1361.000000       0.000000       0.000000       0.000000\n",
       "50%    1787.000000       0.003430       0.005364       0.144000\n",
       "75%    2302.700000       0.004736       0.007081       0.272000\n",
       "max    4807.000000       0.038373       0.068856       4.605000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('year == 2019')[['counts', 'tt_ff', 'tt_avg', 'tf_inrix']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "      <th>tt_ff</th>\n",
       "      <th>tt_avg</th>\n",
       "      <th>tf_inrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9290.000000</td>\n",
       "      <td>159258.000000</td>\n",
       "      <td>159258.000000</td>\n",
       "      <td>159258.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1822.742196</td>\n",
       "      <td>0.003343</td>\n",
       "      <td>0.005127</td>\n",
       "      <td>0.188521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>795.855464</td>\n",
       "      <td>0.003259</td>\n",
       "      <td>0.005394</td>\n",
       "      <td>0.219121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1275.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1715.000000</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>0.005140</td>\n",
       "      <td>0.142000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2242.750000</td>\n",
       "      <td>0.004736</td>\n",
       "      <td>0.006789</td>\n",
       "      <td>0.263000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4798.000000</td>\n",
       "      <td>0.033796</td>\n",
       "      <td>0.067593</td>\n",
       "      <td>3.775000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            counts          tt_ff         tt_avg       tf_inrix\n",
       "count  9290.000000  159258.000000  159258.000000  159258.000000\n",
       "mean   1822.742196       0.003343       0.005127       0.188521\n",
       "std     795.855464       0.003259       0.005394       0.219121\n",
       "min      31.000000       0.000000       0.000000       0.000000\n",
       "25%    1275.125000       0.000000       0.000000       0.000000\n",
       "50%    1715.000000       0.003384       0.005140       0.142000\n",
       "75%    2242.750000       0.004736       0.006789       0.263000\n",
       "max    4798.000000       0.033796       0.067593       3.775000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('year == 2020')[['counts', 'tt_ff', 'tt_avg', 'tf_inrix']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Normalization of features to range [0,1]\n",
    "df[features_Z + ['tt_avg'] + ['tt_ff']] \\\n",
    "    = preprocessing.MinMaxScaler().fit_transform(df[features_Z + ['tt_avg'] + ['tt_ff']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 11:03:28.004836: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "for year in sorted(df['year'].unique()):\n",
    "    df_year = df[df['year'] == year]\n",
    "\n",
    "    n_days, n_hours = len(df_year.date.unique()), len(df_year.hour.unique())\n",
    "\n",
    "    # TODO: Add an assert to check the dataframe is properly sorted before reshaping it into a tensor\n",
    "\n",
    "    traveltime_data = get_y_tensor(y=df_year[['tt_avg']], n_links=n_links, n_days=n_days, n_hours=n_hours)\n",
    "    flow_data = get_y_tensor(y=df_year[['counts']], n_links=n_links, n_days=n_days, n_hours=n_hours)\n",
    "\n",
    "    Y[year] = tf.concat([traveltime_data, flow_data], axis=3)\n",
    "\n",
    "    X[year] = get_design_tensor(Z=df_year[['tt_avg'] + features_Z], n_links=n_links, n_days=n_days, n_hours=n_hours)\n",
    "\n",
    "    # For further internal processing, free flow travel times are stacked as the first feature of matrix X\n",
    "    tt_ff = get_design_tensor(Z=df_year[['tt_ff']], n_links=n_links, n_days=n_days, n_hours=n_hours)\n",
    "    X[year] = tf.concat([tt_ff, X[year]], axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare the training and validation dataset\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = X[2019], X[2020], Y[2019], Y[2020]\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = [tf.constant(i) for i in [X_train, X_val, Y_train, Y_val]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_EPOCHS = 10\n",
    "_BATCH_SIZE = 4\n",
    "_LR = 5e-1  # Default is 1e-3. With 1e-1, training becomes unstable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# models = dict(zip(['m1', 'm2', 'm3', 'm4'], True))\n",
    "models = dict.fromkeys(['m1', 'm2', 'm3', 'm4'], False)\n",
    "models['m1'] = True\n",
    "# models['m2'] = True\n",
    "# models['m3'] = True\n",
    "# models['m4'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# optimizer = tf.keras.optimizers.Adagrad(learning_rate=_LR)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "equilibrator = Equilibrator(\n",
    "    network=fresno_network,\n",
    "    # paths_generator=paths_generator,\n",
    "    utility_function=utility_function,\n",
    "    max_iters=100,\n",
    "    method='fw',\n",
    "    iters_fw=50,\n",
    "    accuracy=1e-4,\n",
    ")\n",
    "\n",
    "column_generator = ColumnGenerator(equilibrator=equilibrator,\n",
    "                                   utility_function=utility_function,\n",
    "                                   n_paths=0,\n",
    "                                   ods_coverage=0.1,\n",
    "                                   ods_sampling='sequential',\n",
    "                                   # ods_sampling='demand',\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_losses_dfs = {}\n",
    "val_losses_dfs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model 1: Benchmark of aesuelogit and isuelogit\n",
      "\n",
      "Epoch: 0\n",
      "0: train_loss=2.3e+06,  val_loss=2.4e+06, train_loss tt=0.015, val_loss tt=0.014, train_loss flow=2.3e+06, val_loss flow=2.4e+06, train_loss bpr=0.0061, val_loss bpr=0.005, avg abs diff demand =8e-16, theta = [0. 0. 0. 0. 0. 0.], psc_factor = 0.0, avg alpha = 0.15, avg beta = 4, time:  14\n",
      "\n",
      "Epoch: 1\n",
      "1: train_loss=1.7e+06,  val_loss=1.7e+06, train_loss tt=0.0062, val_loss tt=0.0057, train_loss flow=1.7e+06, val_loss flow=1.7e+06, train_loss bpr=0.0061, val_loss bpr=0.005, avg abs diff demand =8e-16, theta = [-1.5658 -0.8841  0.     -2.4641  0.     -1.7911], psc_factor = 0.0, avg alpha = 0.15, avg beta = 4, time:  17\n"
     ]
    }
   ],
   "source": [
    "if models['m1']:\n",
    "    print('\\nmodel 1: Benchmark of aesuelogit and isuelogit')\n",
    "\n",
    "    # optimizer = NGD(learning_rate=_LR)\n",
    "\n",
    "    # Model 1 (Utility only)\n",
    "    model_1 = AESUELOGIT(\n",
    "        key='model_1',\n",
    "        network=fresno_network,\n",
    "        dtype=tf.float64,\n",
    "        trainables={'theta': True, 'theta_links': False, 'psc_factor': False, 'q': False, 'alpha': False, 'beta': False},\n",
    "        equilibrator = equilibrator,\n",
    "        column_generator = column_generator,\n",
    "        utility_function=utility_function,\n",
    "        inits={\n",
    "            'q': fresno_network.q.flatten(),\n",
    "            # 'q': 10*np.ones_like(fresno_network.q.flatten()),\n",
    "            'theta': np.array(list(utility_function.initial_values.values())),\n",
    "            'beta': np.array([4]),\n",
    "            'alpha': np.array([0.15])\n",
    "            # 'alpha': np.array([1 for link in fresno_network.links])\n",
    "        },\n",
    "    )\n",
    "\n",
    "    train_losses_dfs['model_1'], val_losses_dfs['model_1'] = model_1.train(\n",
    "        X_train, Y_train, X_val, Y_val,\n",
    "        optimizer=optimizer,\n",
    "        batch_size=_BATCH_SIZE,\n",
    "        lambdas={'od': 0, 'theta': 0, 'tt': 0, 'flow': 1, 'bpr': 0},\n",
    "        epochs=_EPOCHS)\n",
    "\n",
    "    plot_predictive_performance(train_losses=train_losses_dfs['model_1'], val_losses=val_losses_dfs['model_1'])\n",
    "\n",
    "    print(f\"theta = {dict(zip(utility_function.true_values.keys(), list(model_1.theta.numpy())))}\")\n",
    "    print(f\"alpha = {model_1.alpha}, beta  = {model_1.beta}\")\n",
    "    print(\"Avg abs diff between observed and estimated OD:\",\n",
    "          f\"{np.mean(np.abs(model_1.q - fresno_network.q.flatten()))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if models['m2']:\n",
    "    print('\\nmodel 2: OD + utility estimation with historic OD')\n",
    "\n",
    "    model_2 = AESUELOGIT(\n",
    "        key='model_2',\n",
    "        network=fresno_network,\n",
    "        dtype=tf.float64,\n",
    "        trainables={'theta': True, 'theta_links': False, 'q': True, 'alpha': False, 'beta': False},\n",
    "        equilibrator=equilibrator,\n",
    "        column_generator=column_generator,\n",
    "        utility_function=utility_function,\n",
    "        inits={\n",
    "            'q': fresno_network.q.flatten()[np.newaxis,:],\n",
    "            'theta': np.array(list(utility_function.initial_values.values())),\n",
    "            'beta': np.array([4]),\n",
    "            'alpha': np.array([0.15])\n",
    "        },\n",
    "    )\n",
    "\n",
    "    train_losses_dfs['model_2'], val_losses_dfs['model_2'] = model_2.train(\n",
    "        X_train, Y_train, X_val, Y_val,\n",
    "        optimizer=optimizer,\n",
    "        batch_size=_BATCH_SIZE,\n",
    "        lambdas={'od': 1, 'theta': 0, 'tt': 1, 'flow': 1, 'bpr': 0},\n",
    "        epochs=_EPOCHS)\n",
    "\n",
    "    plot_predictive_performance(train_losses=train_losses_dfs['model_2'], val_losses=val_losses_dfs['model_2'])\n",
    "\n",
    "    print(f\"theta = {dict(zip(utility_function.true_values.keys(), list(model_2.theta.numpy())))}\")\n",
    "    print(f\"alpha = {model_2.alpha}, beta  = {model_2.beta}\")\n",
    "    print(\"Avg abs diff between observed and estimated OD:\",\n",
    "          f\"{np.mean(np.abs(model_2.q - fresno_network.q.flatten()))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if models['m3']:\n",
    "\n",
    "    print('\\nmodel 3: ODLUE + link performance parameters without historic OD matrix')\n",
    "\n",
    "    # Model 3 (Utility, ODE, link performance parameters, no historic OD)\n",
    "    model_3 = AESUELOGIT(\n",
    "        key='model_3',\n",
    "        network=fresno_network,\n",
    "        dtype=tf.float64,\n",
    "        trainables={'theta': True, 'theta_links': False, 'psc_factor': True, 'q': True, 'alpha': True, 'beta': True},\n",
    "        equilibrator=equilibrator,\n",
    "        column_generator=column_generator,\n",
    "        utility_function=utility_function,\n",
    "        inits={\n",
    "            'q': fresno_network.q.flatten()[np.newaxis,:],\n",
    "            'theta': np.array(list(utility_function.initial_values.values())),\n",
    "            'beta': np.array([4]),\n",
    "            'alpha': np.array([0.15])\n",
    "        },\n",
    "    )\n",
    "\n",
    "    train_losses_dfs['model_3'], val_losses_dfs['model_3'] = model_3.train(\n",
    "        X_train, Y_train, X_val, Y_val,\n",
    "        optimizer=optimizer,\n",
    "        batch_size=_BATCH_SIZE,\n",
    "        lambdas={'od': 0, 'theta': 0, 'tt': 1, 'flow': 1, 'bpr': 0},\n",
    "        epochs=_EPOCHS)\n",
    "\n",
    "    plot_predictive_performance(train_losses=train_losses_dfs['model_3'], val_losses=val_losses_dfs['model_3'])\n",
    "\n",
    "    print(f\"theta = {dict(zip(utility_function.true_values.keys(), list(model_3.theta.numpy())))}\")\n",
    "    print(f\"alpha = {model_3.alpha}, beta  = {model_3.beta}\")\n",
    "    print(\"Avg abs diff between observed and estimated OD:\",\n",
    "          f\"{np.mean(np.abs(model_3.q - fresno_network.q.flatten()))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if models['m4']:\n",
    "    print('\\nmodel 4: Time specific utility and OD, link performance parameters, no historic OD')\n",
    "\n",
    "    # Model 4 (Time specific Utility and ODE, link performance parameters, no historic OD)\n",
    "    model_4 = AESUELOGIT(\n",
    "        key='model_4',\n",
    "        network=fresno_network,\n",
    "        dtype=tf.float64,\n",
    "        trainables={'theta': True, 'theta_links': False, 'psc_factor': True, 'q': True, 'alpha': True, 'beta': True},\n",
    "        equilibrator=equilibrator,\n",
    "        column_generator=column_generator,\n",
    "        utility_function=utility_function,\n",
    "        inits={\n",
    "            'q': np.repeat(fresno_network.q.flatten()[np.newaxis, :], n_hours, axis=0),\n",
    "            'theta': np.repeat(np.array(list(utility_function.initial_values.values()))[np.newaxis, :], n_hours,\n",
    "                               axis=0),\n",
    "            'beta': np.array([4]),\n",
    "            'alpha': np.array([0.15])\n",
    "        },\n",
    "    )\n",
    "    train_losses_dfs['model_4'], val_losses_dfs['model_4'] = model_4.train(\n",
    "        X_train, Y_train, X_val, Y_val,\n",
    "        optimizer=optimizer,\n",
    "        batch_size=_BATCH_SIZE,\n",
    "        lambdas={'od': 0, 'theta': 0, 'tt': 1, 'flow': 1, 'bpr': 0},\n",
    "        epochs=_EPOCHS)\n",
    "\n",
    "    plot_predictive_performance(train_losses=train_losses_dfs['model_4'], val_losses=val_losses_dfs['model_4'])\n",
    "\n",
    "    print(f\"features = {utility_function.features}\")\n",
    "    print(f\"theta = {model_4.theta.numpy()}\")\n",
    "    print(f\"alpha = {model_4.alpha}, beta  = {model_4.beta}\")\n",
    "    print(\"Avg abs diff between observed and estimated OD:\",\n",
    "          f\"{np.mean(np.abs(model_4.q - fresno_network.q.flatten()))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aesuelogit-1kW0OCrg-py3.9",
   "language": "python",
   "name": "aesuelogit-1kw0ocrg-py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}